{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogLeNet(2014).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7e97fe690fe4a3bb5f0ef0dce8c91d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe0b6eafadce4adb85f60adfd8266dc4",
              "IPY_MODEL_fad5e2f5f99c4ff7bc3509472ea90d11",
              "IPY_MODEL_dbfffd28c89b40dfb4ab1d3aadd11224"
            ],
            "layout": "IPY_MODEL_188e18f5365d4468a74efd134b122136"
          }
        },
        "fe0b6eafadce4adb85f60adfd8266dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af4b2ccfc2d04698866231e871f8ff02",
            "placeholder": "​",
            "style": "IPY_MODEL_3a68f1ee92f84e4e8ead5d78bf6f8cc0",
            "value": "100%"
          }
        },
        "fad5e2f5f99c4ff7bc3509472ea90d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7fe1d4f982d40f599476e58637eb689",
            "max": 2640397119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9644d577f68a4f18b8a229a88dac7521",
            "value": 2640397119
          }
        },
        "dbfffd28c89b40dfb4ab1d3aadd11224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bd95793e4074b60b75ecc84adb60c22",
            "placeholder": "​",
            "style": "IPY_MODEL_9d41e481761d4d72b5bc7cb8177041ee",
            "value": " 2640397119/2640397119 [00:47&lt;00:00, 57379946.63it/s]"
          }
        },
        "188e18f5365d4468a74efd134b122136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4b2ccfc2d04698866231e871f8ff02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a68f1ee92f84e4e8ead5d78bf6f8cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7fe1d4f982d40f599476e58637eb689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9644d577f68a4f18b8a229a88dac7521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bd95793e4074b60b75ecc84adb60c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d41e481761d4d72b5bc7cb8177041ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oc5lTLIo1LN3"
      },
      "outputs": [],
      "source": [
        "# 필요한 모듈을 import하기\n",
        "# 모델과 관련된 모듈 import하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# DataSet 및 DataLoader관련 모듈 import\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# 이미지 출력을 위한 모듈 import\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 기타 모듈 import하기\n",
        "import numpy as np\n",
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 학습과 평가에 STL Dataset을 이용할 것이다\n",
        "# STL Dataset를 저장할 Directory를 명시하도록 하자\n",
        "path2data = \"./data\"\n",
        "\n",
        "if not os.path.exists(path2data):\n",
        "  os.mkdir(path2data)\n",
        "\n",
        "# STL10 Dataset중 train_dataset loading\n",
        "# STL10 Dataset중 validation_dataset loading\n",
        "train_ds = datasets.STL10(path2data, split='train', download=True, transform=transforms.ToTensor())\n",
        "val_ds = datasets.STL10(path2data, split='test', download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b7e97fe690fe4a3bb5f0ef0dce8c91d4",
            "fe0b6eafadce4adb85f60adfd8266dc4",
            "fad5e2f5f99c4ff7bc3509472ea90d11",
            "dbfffd28c89b40dfb4ab1d3aadd11224",
            "188e18f5365d4468a74efd134b122136",
            "af4b2ccfc2d04698866231e871f8ff02",
            "3a68f1ee92f84e4e8ead5d78bf6f8cc0",
            "f7fe1d4f982d40f599476e58637eb689",
            "9644d577f68a4f18b8a229a88dac7521",
            "5bd95793e4074b60b75ecc84adb60c22",
            "9d41e481761d4d72b5bc7cb8177041ee"
          ]
        },
        "id": "wGCKJfEQ1iRD",
        "outputId": "1b3f839a-1aca-4615-ce51-959ffe9a9ecf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2640397119 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7e97fe690fe4a3bb5f0ef0dce8c91d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset을 정규화하기 위하여 각 채널별 평균과 표준편차를 구한다\n",
        "# 우리가 직접 제작한 모델은 STL10 훈련 데이터에 익숙해진 모델이다\n",
        "# 모델이 익숙해하는 훈련 데이터와 같은 RGB로 모든 dataset를 정규화하여야 한다\n",
        "\n",
        "train_meanRGB = [np.mean(x.numpy(),axis=(1,2)) for x, _ in train_ds]\n",
        "train_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_ds]\n",
        "\n",
        "train_meanR = np.mean([m[0] for m in train_meanRGB])\n",
        "train_meanG = np.mean([m[1] for m in train_meanRGB])\n",
        "train_meanB = np.mean([m[2] for m in train_meanRGB])\n",
        "train_stdR = np.std([s[0] for s in train_stdRGB])\n",
        "train_stdG = np.std([s[1] for s in train_stdRGB])\n",
        "train_stdB = np.std([s[2] for s in train_stdRGB])\n",
        "\n",
        "val_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in val_ds]\n",
        "val_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in val_ds]\n",
        "\n",
        "val_meanR = np.mean([m[0] for m in val_meanRGB])\n",
        "val_meanG = np.mean([m[1] for m in val_meanRGB])\n",
        "val_meanB = np.mean([m[2] for m in val_meanRGB])\n",
        "std_meanR = np.std([s[0] for s in val_stdRGB])\n",
        "std_meanG = np.std([s[1] for s in val_stdRGB])\n",
        "std_meanB = np.std([s[2] for s in val_stdRGB])\n",
        "\n",
        "print(train_meanR, train_meanG, train_meanB)\n",
        "print(val_meanR, val_meanG, val_meanB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fZPEVw32bRT",
        "outputId": "1ed234c9-a7bc-4262-c160-e37cacce4c69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4467106 0.43980986 0.40664646\n",
            "0.44723064 0.4396425 0.40495726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset을 불러올 때 사용할 Preprocessor와 DataLoader를 정의하자\n",
        "train_transformation = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Resize(224),\n",
        "                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
        "                        transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "val_transformation = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Resize(224),\n",
        "                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB])                                      \n",
        "])\n",
        "train_ds.transform = train_transformation\n",
        "val_ds.transform = val_transformation\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "cx8Qx_-I4OYt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogLeNet 모델을 정의해보자\n",
        "# 가장 먼저 Channel Reduction Inception Module을 정의할 것인데,\n",
        "# 해당 Inception Module을 구성하는 각 branch에 삽입되는 합성곱층에 Batch normalization과 ReLU를 일괄적으로 적용하기 위하여\n",
        "# 다음과 같은 클래스를 정의하였다.\n",
        "\n",
        "# Convolution Layer의 여러 Parameter는 kwargs라는 이름의 파라미터로 받게 된다.\n",
        "class conv_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels,**kwargs):\n",
        "    super(conv_block, self).__init__()\n",
        "\n",
        "    self.conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, **kwargs),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv_layer(x)\n"
      ],
      "metadata": {
        "id": "Tuj59mxxjRZC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduced Dimension inception module을 정의한다\n",
        "# 각 parameter 설명\n",
        "# out_1x1 : 첫 번째 branch의 최종 출력 채널\n",
        "# red_3x3, out_3x3 : 두 번째 branch의 중간, 최종 출력 채널\n",
        "# red_5x5, out_5x5 : 세 번째 branch의 중간, 최종 출력 채널\n",
        "# out_1x1pool : 네 번째 branch의 최종 출력 채널\n",
        "\n",
        "class Inception_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
        "    super(Inception_block, self).__init__()\n",
        "\n",
        "    # GoogLeNet의 inception Module은 총 4개의 branch의 출력을 채널 방향으로 Concatanate한다\n",
        "    # 첫 번째 branch 정의하기\n",
        "    self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
        "\n",
        "    # 두 번째 branch 정의하기\n",
        "    # 각 branch의 padding은 출력 형상을 입력과 일치시키기 위해 설정한 것이다\n",
        "    self.branch2 = nn.Sequential(\n",
        "        conv_block(in_channels, red_3x3, kernel_size=1),\n",
        "        conv_block(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
        "    )\n",
        "\n",
        "    self.branch3 = nn.Sequential(\n",
        "        conv_block(in_channels, red_5x5, kernel_size=1),\n",
        "        conv_block(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
        "    )\n",
        "\n",
        "    self.branch4 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        conv_block(in_channels, out_1x1pool, kernel_size=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x의 차원은 (Batch_size, Channel, Width, Height)로 구성되어 있다\n",
        "    # 각 branch의 출력을 channel방향으로 concatenate하여 다음 Layer로 전달한다\n",
        "    x = torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)],1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "bDzpIO-glAZ5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogLeNet만의 특수한 구조 Auxiliary classifier\n",
        "# auxiliary classifier에 의한 학습 시 loss에는 0.3을 곱하여 영향을 최소화한다\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super(InceptionAux, self).__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "        conv_block(in_channels, 128, kernel_size=1)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(2048,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(1024, num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5zW-2SDMpPUZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogLeNet의 network in network에 사용되는 여러 모듈을 정의하였다\n",
        "# 이제 GoogLeNet을 정의해보자\n",
        "# aux_logits : 해당 GoogLeNet모델에 Auxiliary Classifier를 적용할지 여부를 선택한다\n",
        "# True이면 해당 모델 내에 Auxiliary Classifier를 설치한다\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "  def __init__(self, aux_logits=True, num_classes=10, init_weights=True):\n",
        "    super(GoogLeNet, self).__init__()\n",
        "\n",
        "    # aux_logits값이 True 또는 False이어야 한다\n",
        "    assert aux_logits == True or aux_logits == False\n",
        "    self.aux_logits = aux_logits\n",
        "\n",
        "    # GoogLeNet의 전체 Layer 정의하기\n",
        "    # Auxiliary Classifier는 inception 4b, 4e와 연결 되어있다\n",
        "    self.conv1 = conv_block(3,64,kernel_size=7, stride=2, padding=3)\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.conv2 = conv_block(64,192, kernel_size=3, stride=1, padding=1)\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "    self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "\n",
        "    self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "    self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "    self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "\n",
        "    self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128 )\n",
        "    self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "    self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.fc1 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    # GoogLeNet에 Auxiliary Classifier를 설정할지 여부에 따라 모델을 다르게 만든다\n",
        "    if self.aux_logits:\n",
        "      self.aux1 = InceptionAux(512, num_classes) # 입력채널 수가 Inception_4b와 같다\n",
        "      self.aux2 = InceptionAux(528, num_classes) # 입력채널 수가 Inception_4e와 같다\n",
        "    else :\n",
        "      self.aux1 = self.aux2 = None\n",
        "\n",
        "    # weight initialization\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.inception3a(x)\n",
        "    x = self.inception3b(x)\n",
        "    x = self.maxpool3(x)\n",
        "    x = self.inception4a(x)\n",
        "\n",
        "    # 만약 Auxiliary Classifier가 적용되어 있고, 학습 모드라면\n",
        "    # 첫 번째 Auxiliary Classifier의 결과를 저장한다\n",
        "\n",
        "    if self.aux_logits and self.training:\n",
        "      aux1 = self.aux1(x)\n",
        "\n",
        "    x = self.inception4b(x)\n",
        "    x = self.inception4c(x)\n",
        "    x = self.inception4d(x)\n",
        "\n",
        "    # 만약 Auxiliary Classifier가 적용되어 있고, 학습 모드라면\n",
        "    # 두 번째 Auxiliary Classifier의 결과를 저장한다\n",
        "    if self.aux_logits and self.training:\n",
        "        aux2 = self.aux2(x)\n",
        "\n",
        "    x = self.inception4e(x)\n",
        "    x = self.maxpool4(x)\n",
        "    x = self.inception5a(x)\n",
        "    x = self.inception5b(x)\n",
        "    x = self.avgpool(x)\n",
        "\n",
        "    x = x.view(x.shape[0], -1)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc1(x) # 실제 Classifier\n",
        "    \n",
        "    if self.aux_logits and self.training:\n",
        "      return (x, aux1, aux2)\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "  # GoogLeNet모델의 가중치를 초기화 해주는 인스턴스 함수를 정의한다\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        # 모델의 가중치를 초기화하는 함수 (다시 공부 필요)\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias,0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight,1)\n",
        "        nn.init.constant_(m.bias,0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.constant_(m.bias,0)\n"
      ],
      "metadata": {
        "id": "se4F7V-bsGHp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device를 정의 및 모델을 생성한다\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GoogLeNet(aux_logits=True, num_classes=10, init_weights=True).to(device)"
      ],
      "metadata": {
        "id": "HOnmaHE083q7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model이 올바르게 정의되었는지 확인하기 위하여 임의의 input을 통과시켜 보자\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cT70jZQ9xmZ",
        "outputId": "cf1b72f0-3a9f-4e63-a45c-07915f2f0fcb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.2224, -0.1502,  0.0301, -0.4078, -0.2194,  0.1947, -0.0490,  0.0588,\n",
            "          0.1062, -0.1923],\n",
            "        [-0.0570,  0.0353, -0.1919,  0.0025,  0.0260,  0.2307, -0.1039,  0.2329,\n",
            "          0.0445, -0.0623],\n",
            "        [-0.3132, -0.1867,  0.1086, -0.0915, -0.0176, -0.1184, -0.0013,  0.2148,\n",
            "          0.0528,  0.1562]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[-0.0499,  0.1645, -0.0970,  0.1916,  0.0415,  0.2317, -0.1784,  0.0272,\n",
            "          0.2067, -0.0881],\n",
            "        [ 0.0105,  0.0901,  0.2227,  0.0448,  0.0789,  0.0290,  0.0025, -0.0504,\n",
            "          0.0767, -0.0581],\n",
            "        [ 0.1101,  0.1109, -0.0905, -0.0021,  0.2313, -0.0588,  0.0480,  0.0091,\n",
            "          0.0940, -0.0291]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[-0.0520,  0.2617,  0.0231, -0.1939,  0.0200, -0.0372,  0.0735, -0.0772,\n",
            "         -0.2404,  0.0233],\n",
            "        [-0.1309,  0.0207, -0.0321,  0.0853, -0.0133, -0.0062,  0.0178,  0.0188,\n",
            "         -0.0639,  0.0666],\n",
            "        [-0.1521,  0.1329,  0.0118,  0.0939, -0.1063, -0.0961, -0.1725, -0.1026,\n",
            "          0.0339,  0.0669]], device='cuda:0', grad_fn=<AddmmBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model을 print하여 전체 구조 파악\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62iNUp0z967j",
        "outputId": "b9790564-3706-45d6-c702-85e44a7df451"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GoogLeNet(\n",
            "  (conv1): conv_block(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): conv_block(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (inception3a): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception3b): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (inception4a): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4b): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4c): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4d): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4e): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (inception5a): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception5b): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  (aux1): InceptionAux(\n",
            "    (conv): Sequential(\n",
            "      (0): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (aux2): InceptionAux(\n",
            "    (conv): Sequential(\n",
            "      (0): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchsummary이용하여 임의의 입력값이 input되었을 때 어떠한 형태로 처리되는지 확인한다\n",
        "summary(model, input_size=(3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eam3Xsq2-GHC",
        "outputId": "845612bc-4a09-46d9-c482-7c4bb2ff54c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "        conv_block-4         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
            "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
            "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
            "              ReLU-8          [-1, 192, 56, 56]               0\n",
            "        conv_block-9          [-1, 192, 56, 56]               0\n",
            "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
            "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
            "      BatchNorm2d-12           [-1, 64, 28, 28]             128\n",
            "             ReLU-13           [-1, 64, 28, 28]               0\n",
            "       conv_block-14           [-1, 64, 28, 28]               0\n",
            "           Conv2d-15           [-1, 96, 28, 28]          18,528\n",
            "      BatchNorm2d-16           [-1, 96, 28, 28]             192\n",
            "             ReLU-17           [-1, 96, 28, 28]               0\n",
            "       conv_block-18           [-1, 96, 28, 28]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]         110,720\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "       conv_block-22          [-1, 128, 28, 28]               0\n",
            "           Conv2d-23           [-1, 16, 28, 28]           3,088\n",
            "      BatchNorm2d-24           [-1, 16, 28, 28]              32\n",
            "             ReLU-25           [-1, 16, 28, 28]               0\n",
            "       conv_block-26           [-1, 16, 28, 28]               0\n",
            "           Conv2d-27           [-1, 32, 28, 28]          12,832\n",
            "      BatchNorm2d-28           [-1, 32, 28, 28]              64\n",
            "             ReLU-29           [-1, 32, 28, 28]               0\n",
            "       conv_block-30           [-1, 32, 28, 28]               0\n",
            "        MaxPool2d-31          [-1, 192, 28, 28]               0\n",
            "           Conv2d-32           [-1, 32, 28, 28]           6,176\n",
            "      BatchNorm2d-33           [-1, 32, 28, 28]              64\n",
            "             ReLU-34           [-1, 32, 28, 28]               0\n",
            "       conv_block-35           [-1, 32, 28, 28]               0\n",
            "  Inception_block-36          [-1, 256, 28, 28]               0\n",
            "           Conv2d-37          [-1, 128, 28, 28]          32,896\n",
            "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
            "             ReLU-39          [-1, 128, 28, 28]               0\n",
            "       conv_block-40          [-1, 128, 28, 28]               0\n",
            "           Conv2d-41          [-1, 128, 28, 28]          32,896\n",
            "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
            "             ReLU-43          [-1, 128, 28, 28]               0\n",
            "       conv_block-44          [-1, 128, 28, 28]               0\n",
            "           Conv2d-45          [-1, 192, 28, 28]         221,376\n",
            "      BatchNorm2d-46          [-1, 192, 28, 28]             384\n",
            "             ReLU-47          [-1, 192, 28, 28]               0\n",
            "       conv_block-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49           [-1, 32, 28, 28]           8,224\n",
            "      BatchNorm2d-50           [-1, 32, 28, 28]              64\n",
            "             ReLU-51           [-1, 32, 28, 28]               0\n",
            "       conv_block-52           [-1, 32, 28, 28]               0\n",
            "           Conv2d-53           [-1, 96, 28, 28]          76,896\n",
            "      BatchNorm2d-54           [-1, 96, 28, 28]             192\n",
            "             ReLU-55           [-1, 96, 28, 28]               0\n",
            "       conv_block-56           [-1, 96, 28, 28]               0\n",
            "        MaxPool2d-57          [-1, 256, 28, 28]               0\n",
            "           Conv2d-58           [-1, 64, 28, 28]          16,448\n",
            "      BatchNorm2d-59           [-1, 64, 28, 28]             128\n",
            "             ReLU-60           [-1, 64, 28, 28]               0\n",
            "       conv_block-61           [-1, 64, 28, 28]               0\n",
            "  Inception_block-62          [-1, 480, 28, 28]               0\n",
            "        MaxPool2d-63          [-1, 480, 14, 14]               0\n",
            "           Conv2d-64          [-1, 192, 14, 14]          92,352\n",
            "      BatchNorm2d-65          [-1, 192, 14, 14]             384\n",
            "             ReLU-66          [-1, 192, 14, 14]               0\n",
            "       conv_block-67          [-1, 192, 14, 14]               0\n",
            "           Conv2d-68           [-1, 96, 14, 14]          46,176\n",
            "      BatchNorm2d-69           [-1, 96, 14, 14]             192\n",
            "             ReLU-70           [-1, 96, 14, 14]               0\n",
            "       conv_block-71           [-1, 96, 14, 14]               0\n",
            "           Conv2d-72          [-1, 208, 14, 14]         179,920\n",
            "      BatchNorm2d-73          [-1, 208, 14, 14]             416\n",
            "             ReLU-74          [-1, 208, 14, 14]               0\n",
            "       conv_block-75          [-1, 208, 14, 14]               0\n",
            "           Conv2d-76           [-1, 16, 14, 14]           7,696\n",
            "      BatchNorm2d-77           [-1, 16, 14, 14]              32\n",
            "             ReLU-78           [-1, 16, 14, 14]               0\n",
            "       conv_block-79           [-1, 16, 14, 14]               0\n",
            "           Conv2d-80           [-1, 48, 14, 14]          19,248\n",
            "      BatchNorm2d-81           [-1, 48, 14, 14]              96\n",
            "             ReLU-82           [-1, 48, 14, 14]               0\n",
            "       conv_block-83           [-1, 48, 14, 14]               0\n",
            "        MaxPool2d-84          [-1, 480, 14, 14]               0\n",
            "           Conv2d-85           [-1, 64, 14, 14]          30,784\n",
            "      BatchNorm2d-86           [-1, 64, 14, 14]             128\n",
            "             ReLU-87           [-1, 64, 14, 14]               0\n",
            "       conv_block-88           [-1, 64, 14, 14]               0\n",
            "  Inception_block-89          [-1, 512, 14, 14]               0\n",
            "        AvgPool2d-90            [-1, 512, 4, 4]               0\n",
            "           Conv2d-91            [-1, 128, 4, 4]          65,664\n",
            "      BatchNorm2d-92            [-1, 128, 4, 4]             256\n",
            "             ReLU-93            [-1, 128, 4, 4]               0\n",
            "       conv_block-94            [-1, 128, 4, 4]               0\n",
            "           Linear-95                 [-1, 1024]       2,098,176\n",
            "             ReLU-96                 [-1, 1024]               0\n",
            "          Dropout-97                 [-1, 1024]               0\n",
            "           Linear-98                   [-1, 10]          10,250\n",
            "     InceptionAux-99                   [-1, 10]               0\n",
            "          Conv2d-100          [-1, 160, 14, 14]          82,080\n",
            "     BatchNorm2d-101          [-1, 160, 14, 14]             320\n",
            "            ReLU-102          [-1, 160, 14, 14]               0\n",
            "      conv_block-103          [-1, 160, 14, 14]               0\n",
            "          Conv2d-104          [-1, 112, 14, 14]          57,456\n",
            "     BatchNorm2d-105          [-1, 112, 14, 14]             224\n",
            "            ReLU-106          [-1, 112, 14, 14]               0\n",
            "      conv_block-107          [-1, 112, 14, 14]               0\n",
            "          Conv2d-108          [-1, 224, 14, 14]         226,016\n",
            "     BatchNorm2d-109          [-1, 224, 14, 14]             448\n",
            "            ReLU-110          [-1, 224, 14, 14]               0\n",
            "      conv_block-111          [-1, 224, 14, 14]               0\n",
            "          Conv2d-112           [-1, 24, 14, 14]          12,312\n",
            "     BatchNorm2d-113           [-1, 24, 14, 14]              48\n",
            "            ReLU-114           [-1, 24, 14, 14]               0\n",
            "      conv_block-115           [-1, 24, 14, 14]               0\n",
            "          Conv2d-116           [-1, 64, 14, 14]          38,464\n",
            "     BatchNorm2d-117           [-1, 64, 14, 14]             128\n",
            "            ReLU-118           [-1, 64, 14, 14]               0\n",
            "      conv_block-119           [-1, 64, 14, 14]               0\n",
            "       MaxPool2d-120          [-1, 512, 14, 14]               0\n",
            "          Conv2d-121           [-1, 64, 14, 14]          32,832\n",
            "     BatchNorm2d-122           [-1, 64, 14, 14]             128\n",
            "            ReLU-123           [-1, 64, 14, 14]               0\n",
            "      conv_block-124           [-1, 64, 14, 14]               0\n",
            " Inception_block-125          [-1, 512, 14, 14]               0\n",
            "          Conv2d-126          [-1, 128, 14, 14]          65,664\n",
            "     BatchNorm2d-127          [-1, 128, 14, 14]             256\n",
            "            ReLU-128          [-1, 128, 14, 14]               0\n",
            "      conv_block-129          [-1, 128, 14, 14]               0\n",
            "          Conv2d-130          [-1, 128, 14, 14]          65,664\n",
            "     BatchNorm2d-131          [-1, 128, 14, 14]             256\n",
            "            ReLU-132          [-1, 128, 14, 14]               0\n",
            "      conv_block-133          [-1, 128, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         295,168\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "      conv_block-137          [-1, 256, 14, 14]               0\n",
            "          Conv2d-138           [-1, 24, 14, 14]          12,312\n",
            "     BatchNorm2d-139           [-1, 24, 14, 14]              48\n",
            "            ReLU-140           [-1, 24, 14, 14]               0\n",
            "      conv_block-141           [-1, 24, 14, 14]               0\n",
            "          Conv2d-142           [-1, 64, 14, 14]          38,464\n",
            "     BatchNorm2d-143           [-1, 64, 14, 14]             128\n",
            "            ReLU-144           [-1, 64, 14, 14]               0\n",
            "      conv_block-145           [-1, 64, 14, 14]               0\n",
            "       MaxPool2d-146          [-1, 512, 14, 14]               0\n",
            "          Conv2d-147           [-1, 64, 14, 14]          32,832\n",
            "     BatchNorm2d-148           [-1, 64, 14, 14]             128\n",
            "            ReLU-149           [-1, 64, 14, 14]               0\n",
            "      conv_block-150           [-1, 64, 14, 14]               0\n",
            " Inception_block-151          [-1, 512, 14, 14]               0\n",
            "          Conv2d-152          [-1, 112, 14, 14]          57,456\n",
            "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
            "            ReLU-154          [-1, 112, 14, 14]               0\n",
            "      conv_block-155          [-1, 112, 14, 14]               0\n",
            "          Conv2d-156          [-1, 144, 14, 14]          73,872\n",
            "     BatchNorm2d-157          [-1, 144, 14, 14]             288\n",
            "            ReLU-158          [-1, 144, 14, 14]               0\n",
            "      conv_block-159          [-1, 144, 14, 14]               0\n",
            "          Conv2d-160          [-1, 288, 14, 14]         373,536\n",
            "     BatchNorm2d-161          [-1, 288, 14, 14]             576\n",
            "            ReLU-162          [-1, 288, 14, 14]               0\n",
            "      conv_block-163          [-1, 288, 14, 14]               0\n",
            "          Conv2d-164           [-1, 32, 14, 14]          16,416\n",
            "     BatchNorm2d-165           [-1, 32, 14, 14]              64\n",
            "            ReLU-166           [-1, 32, 14, 14]               0\n",
            "      conv_block-167           [-1, 32, 14, 14]               0\n",
            "          Conv2d-168           [-1, 64, 14, 14]          51,264\n",
            "     BatchNorm2d-169           [-1, 64, 14, 14]             128\n",
            "            ReLU-170           [-1, 64, 14, 14]               0\n",
            "      conv_block-171           [-1, 64, 14, 14]               0\n",
            "       MaxPool2d-172          [-1, 512, 14, 14]               0\n",
            "          Conv2d-173           [-1, 64, 14, 14]          32,832\n",
            "     BatchNorm2d-174           [-1, 64, 14, 14]             128\n",
            "            ReLU-175           [-1, 64, 14, 14]               0\n",
            "      conv_block-176           [-1, 64, 14, 14]               0\n",
            " Inception_block-177          [-1, 528, 14, 14]               0\n",
            "       AvgPool2d-178            [-1, 528, 4, 4]               0\n",
            "          Conv2d-179            [-1, 128, 4, 4]          67,712\n",
            "     BatchNorm2d-180            [-1, 128, 4, 4]             256\n",
            "            ReLU-181            [-1, 128, 4, 4]               0\n",
            "      conv_block-182            [-1, 128, 4, 4]               0\n",
            "          Linear-183                 [-1, 1024]       2,098,176\n",
            "            ReLU-184                 [-1, 1024]               0\n",
            "         Dropout-185                 [-1, 1024]               0\n",
            "          Linear-186                   [-1, 10]          10,250\n",
            "    InceptionAux-187                   [-1, 10]               0\n",
            "          Conv2d-188          [-1, 256, 14, 14]         135,424\n",
            "     BatchNorm2d-189          [-1, 256, 14, 14]             512\n",
            "            ReLU-190          [-1, 256, 14, 14]               0\n",
            "      conv_block-191          [-1, 256, 14, 14]               0\n",
            "          Conv2d-192          [-1, 160, 14, 14]          84,640\n",
            "     BatchNorm2d-193          [-1, 160, 14, 14]             320\n",
            "            ReLU-194          [-1, 160, 14, 14]               0\n",
            "      conv_block-195          [-1, 160, 14, 14]               0\n",
            "          Conv2d-196          [-1, 320, 14, 14]         461,120\n",
            "     BatchNorm2d-197          [-1, 320, 14, 14]             640\n",
            "            ReLU-198          [-1, 320, 14, 14]               0\n",
            "      conv_block-199          [-1, 320, 14, 14]               0\n",
            "          Conv2d-200           [-1, 32, 14, 14]          16,928\n",
            "     BatchNorm2d-201           [-1, 32, 14, 14]              64\n",
            "            ReLU-202           [-1, 32, 14, 14]               0\n",
            "      conv_block-203           [-1, 32, 14, 14]               0\n",
            "          Conv2d-204          [-1, 128, 14, 14]         102,528\n",
            "     BatchNorm2d-205          [-1, 128, 14, 14]             256\n",
            "            ReLU-206          [-1, 128, 14, 14]               0\n",
            "      conv_block-207          [-1, 128, 14, 14]               0\n",
            "       MaxPool2d-208          [-1, 528, 14, 14]               0\n",
            "          Conv2d-209          [-1, 128, 14, 14]          67,712\n",
            "     BatchNorm2d-210          [-1, 128, 14, 14]             256\n",
            "            ReLU-211          [-1, 128, 14, 14]               0\n",
            "      conv_block-212          [-1, 128, 14, 14]               0\n",
            " Inception_block-213          [-1, 832, 14, 14]               0\n",
            "       MaxPool2d-214            [-1, 832, 7, 7]               0\n",
            "          Conv2d-215            [-1, 256, 7, 7]         213,248\n",
            "     BatchNorm2d-216            [-1, 256, 7, 7]             512\n",
            "            ReLU-217            [-1, 256, 7, 7]               0\n",
            "      conv_block-218            [-1, 256, 7, 7]               0\n",
            "          Conv2d-219            [-1, 160, 7, 7]         133,280\n",
            "     BatchNorm2d-220            [-1, 160, 7, 7]             320\n",
            "            ReLU-221            [-1, 160, 7, 7]               0\n",
            "      conv_block-222            [-1, 160, 7, 7]               0\n",
            "          Conv2d-223            [-1, 320, 7, 7]         461,120\n",
            "     BatchNorm2d-224            [-1, 320, 7, 7]             640\n",
            "            ReLU-225            [-1, 320, 7, 7]               0\n",
            "      conv_block-226            [-1, 320, 7, 7]               0\n",
            "          Conv2d-227             [-1, 32, 7, 7]          26,656\n",
            "     BatchNorm2d-228             [-1, 32, 7, 7]              64\n",
            "            ReLU-229             [-1, 32, 7, 7]               0\n",
            "      conv_block-230             [-1, 32, 7, 7]               0\n",
            "          Conv2d-231            [-1, 128, 7, 7]         102,528\n",
            "     BatchNorm2d-232            [-1, 128, 7, 7]             256\n",
            "            ReLU-233            [-1, 128, 7, 7]               0\n",
            "      conv_block-234            [-1, 128, 7, 7]               0\n",
            "       MaxPool2d-235            [-1, 832, 7, 7]               0\n",
            "          Conv2d-236            [-1, 128, 7, 7]         106,624\n",
            "     BatchNorm2d-237            [-1, 128, 7, 7]             256\n",
            "            ReLU-238            [-1, 128, 7, 7]               0\n",
            "      conv_block-239            [-1, 128, 7, 7]               0\n",
            " Inception_block-240            [-1, 832, 7, 7]               0\n",
            "          Conv2d-241            [-1, 384, 7, 7]         319,872\n",
            "     BatchNorm2d-242            [-1, 384, 7, 7]             768\n",
            "            ReLU-243            [-1, 384, 7, 7]               0\n",
            "      conv_block-244            [-1, 384, 7, 7]               0\n",
            "          Conv2d-245            [-1, 192, 7, 7]         159,936\n",
            "     BatchNorm2d-246            [-1, 192, 7, 7]             384\n",
            "            ReLU-247            [-1, 192, 7, 7]               0\n",
            "      conv_block-248            [-1, 192, 7, 7]               0\n",
            "          Conv2d-249            [-1, 384, 7, 7]         663,936\n",
            "     BatchNorm2d-250            [-1, 384, 7, 7]             768\n",
            "            ReLU-251            [-1, 384, 7, 7]               0\n",
            "      conv_block-252            [-1, 384, 7, 7]               0\n",
            "          Conv2d-253             [-1, 48, 7, 7]          39,984\n",
            "     BatchNorm2d-254             [-1, 48, 7, 7]              96\n",
            "            ReLU-255             [-1, 48, 7, 7]               0\n",
            "      conv_block-256             [-1, 48, 7, 7]               0\n",
            "          Conv2d-257            [-1, 128, 7, 7]         153,728\n",
            "     BatchNorm2d-258            [-1, 128, 7, 7]             256\n",
            "            ReLU-259            [-1, 128, 7, 7]               0\n",
            "      conv_block-260            [-1, 128, 7, 7]               0\n",
            "       MaxPool2d-261            [-1, 832, 7, 7]               0\n",
            "          Conv2d-262            [-1, 128, 7, 7]         106,624\n",
            "     BatchNorm2d-263            [-1, 128, 7, 7]             256\n",
            "            ReLU-264            [-1, 128, 7, 7]               0\n",
            "      conv_block-265            [-1, 128, 7, 7]               0\n",
            " Inception_block-266           [-1, 1024, 7, 7]               0\n",
            "       AvgPool2d-267           [-1, 1024, 1, 1]               0\n",
            "         Dropout-268                 [-1, 1024]               0\n",
            "          Linear-269                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 10,344,814\n",
            "Trainable params: 10,344,814\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 112.89\n",
            "Params size (MB): 39.46\n",
            "Estimated Total Size (MB): 152.92\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 본격적으로 학습을 위한 함수를 제작하자\n",
        "# 하나의 batch_set의 데이터들의 손실함수가 모두 합산되어 반환되도록 정의\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "# 30회마다 Learning rate를 10분의 1로 줄여주는 Scheduler 제작\n",
        "lr_scheduler = StepLR(opt, step_size=30, gamma=0.1)\n",
        "\n",
        "# optimizer의 현재 Learning rate를 반환하는 함수 제작\n",
        "def get_lr(opt):\n",
        "  return opt.param_groups[0]['lr']\n",
        "\n",
        "# model의 예측과 정답 label을 비교하여 맞춘 개수를 반환한다\n",
        "def metric_batch(output, target):\n",
        "  pred = output.argmax(dim=1, keepdim=True)\n",
        "  corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "  return corrects\n",
        "\n",
        "# batct학습 시 손실함수 이용하여 backpropagation을 하고 나서\n",
        "# 해당 batch의 총 loss값과 맞은 정답의 개수를 반환하는 함수\n",
        "\n",
        "def loss_batch(loss_func, outputs, target, opt=None):\n",
        "  # 만약 Auxiliary Classifier가 적용된 모델이 반환한 값이라면\n",
        "  # Main Classifier의 반환값, Aux. classifier 1,2의 반환값이 return된다\n",
        "  if len(outputs) == 3:\n",
        "    output, aux1, aux2 = outputs\n",
        "  \n",
        "    output_loss = loss_func(output, target)\n",
        "    aux1_loss = loss_func(aux1, target)\n",
        "    aux2_loss = loss_func(aux2, target)\n",
        "\n",
        "    # Aux. Classifier의 loss는 0.3을 곱하여 전체 loss에 더한다\n",
        "    loss = output_loss + 0.3*(aux1_loss + aux2_loss)\n",
        "\n",
        "    # 해당 batch_dataset에서 model이 맞춘 정답의 개수\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "  else:\n",
        "    loss = loss_func(outputs, target)\n",
        "    metric_b = metric_batch(outputs, target)\n",
        "\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "  return loss.item(), metric_b\n",
        "\n",
        "# 해당 dataloader를 이용해 model을 1 epoch 훈련시키고\n",
        "# 1epoch동안의 평균 손실함수값과 정확도를 반환하는 함수\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "  # epoch 동안의 평균 손실함수값\n",
        "  # epoch 동안의 평균 Precision 저장을 위한 변수 생성\n",
        "  running_loss = 0.0\n",
        "  running_metric = 0.0\n",
        "  len_data = len(dataset_dl.dataset)\n",
        "\n",
        "  for xb, yb in dataset_dl:\n",
        "    xb, yb = xb.to(device), yb.to(device)\n",
        "    output = model(xb)\n",
        "\n",
        "    loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "    running_loss += loss_b\n",
        "\n",
        "    if metric_b is not None:\n",
        "      running_metric += metric_b\n",
        "\n",
        "    if sanity_check is True:\n",
        "      break\n",
        "\n",
        "  loss = running_loss  / len_data\n",
        "  metric = running_metric / len_data\n",
        "\n",
        "  return loss, metric\n",
        "\n",
        "# configuration parameter를 params라는 인자로 전달하면\n",
        "# 해당 config에 맞게 Train을 해주는 함수를 정의하였다\n",
        "def train_val(model, params):\n",
        "  num_epochs=params[\"num_epochs\"]\n",
        "  loss_func=params[\"loss_func\"]\n",
        "  opt=params[\"optimizer\"]\n",
        "  train_dl=params[\"train_dl\"]\n",
        "  val_dl=params[\"val_dl\"]\n",
        "  sanity_check=params[\"sanity_check\"]\n",
        "  lr_scheduler=params[\"lr_scheduler\"]\n",
        "  path2weights=params[\"path2weights\"]\n",
        "\n",
        "  # epoch별 평균 loss와 정확도를 저장\n",
        "  loss_history = {'train':[], 'val':[]}\n",
        "  metric_history = {'train':[], 'val':[]}\n",
        "\n",
        "  # 가장 작은 손실함수값을 반환하는 모델의 가중치를 저장한다\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = float('inf')\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr)) \n",
        "\n",
        "    # 학습 모드\n",
        "    model.train()\n",
        "    # train_dataset 1 Epoch 훈련\n",
        "    train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "    \n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # 모델의 성능 평가모드\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      torch.save(model.state_dict(), path2weights)\n",
        "      print(\"Copied best model weights!\")\n",
        "\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)\n",
        "\n",
        "  # 학습을 모두 마치기 전 가장 손실함수가 적게 반환된 가중치로 모델을 초기화한다\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model, loss_history, metric_history\n",
        "\n"
      ],
      "metadata": {
        "id": "agiJc6kD_pH1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습함수의 configuration으로 적용할 parameter를 만든다\n",
        "params_train = {\n",
        "    'num_epochs':50,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# best_weights를 저장할 디렉토리를 생성한다\n",
        "def createFolder(dir_path):\n",
        "  try:\n",
        "    if not os.path.exists(dir_path):\n",
        "      os.makedirs(dir_path)\n",
        "  except OSerror:\n",
        "    print(\"Error\")\n",
        "createFolder(\"./models\")"
      ],
      "metadata": {
        "id": "AW-qMdEpFjhM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "id": "Bwi3OQ9BI-CD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0dc619-8c36-42a0-8418-95ee4dfdd055"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 2.774134, val loss: 1.772952, accuracy: 30.49, time: 0.8177 min\n",
            "----------\n",
            "Epoch 1/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 2.325948, val loss: 1.643793, accuracy: 41.08, time: 1.6073 min\n",
            "----------\n",
            "Epoch 2/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 2.079945, val loss: 1.369010, accuracy: 49.04, time: 2.3968 min\n",
            "----------\n",
            "Epoch 3/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 1.870917, val loss: 1.363517, accuracy: 53.05, time: 3.1875 min\n",
            "----------\n",
            "Epoch 4/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 1.693205, val loss: 1.312639, accuracy: 54.36, time: 3.9822 min\n",
            "----------\n",
            "Epoch 5/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 1.525838, val loss: 1.248575, accuracy: 56.10, time: 4.7768 min\n",
            "----------\n",
            "Epoch 6/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 1.433418, val loss: 1.010976, accuracy: 64.41, time: 5.5713 min\n",
            "----------\n",
            "Epoch 7/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 1.326028, val loss: 0.942739, accuracy: 66.71, time: 6.3668 min\n",
            "----------\n",
            "Epoch 8/49, current lr=0.001\n",
            "train loss: 1.209190, val loss: 1.318595, accuracy: 58.43, time: 7.1593 min\n",
            "----------\n",
            "Epoch 9/49, current lr=0.001\n",
            "train loss: 1.097422, val loss: 0.994660, accuracy: 67.36, time: 7.9492 min\n",
            "----------\n",
            "Epoch 10/49, current lr=0.001\n",
            "train loss: 1.037391, val loss: 1.012555, accuracy: 65.62, time: 8.7366 min\n",
            "----------\n",
            "Epoch 11/49, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.930560, val loss: 0.883473, accuracy: 70.96, time: 9.5270 min\n",
            "----------\n",
            "Epoch 12/49, current lr=0.001\n",
            "train loss: 0.826127, val loss: 0.974132, accuracy: 69.20, time: 10.3148 min\n",
            "----------\n",
            "Epoch 13/49, current lr=0.001\n",
            "train loss: 0.745415, val loss: 0.941998, accuracy: 69.73, time: 11.1024 min\n",
            "----------\n",
            "Epoch 14/49, current lr=0.001\n",
            "train loss: 0.694945, val loss: 0.917657, accuracy: 71.61, time: 11.8912 min\n",
            "----------\n",
            "Epoch 15/49, current lr=0.001\n",
            "train loss: 0.598674, val loss: 0.922621, accuracy: 72.86, time: 12.6807 min\n",
            "----------\n",
            "Epoch 16/49, current lr=0.001\n",
            "train loss: 0.562372, val loss: 1.326838, accuracy: 65.22, time: 13.4722 min\n",
            "----------\n",
            "Epoch 17/49, current lr=0.001\n",
            "train loss: 0.486066, val loss: 1.235540, accuracy: 68.20, time: 14.2611 min\n",
            "----------\n",
            "Epoch 18/49, current lr=0.001\n",
            "train loss: 0.441350, val loss: 1.274027, accuracy: 66.84, time: 15.0493 min\n",
            "----------\n",
            "Epoch 19/49, current lr=0.001\n",
            "train loss: 0.395225, val loss: 1.176183, accuracy: 69.77, time: 15.8376 min\n",
            "----------\n",
            "Epoch 20/49, current lr=0.001\n",
            "train loss: 0.374493, val loss: 1.272180, accuracy: 68.56, time: 16.6243 min\n",
            "----------\n",
            "Epoch 21/49, current lr=0.001\n",
            "train loss: 0.312973, val loss: 1.229649, accuracy: 71.56, time: 17.4129 min\n",
            "----------\n",
            "Epoch 22/49, current lr=0.001\n",
            "train loss: 0.323112, val loss: 1.127255, accuracy: 71.34, time: 18.2004 min\n",
            "----------\n",
            "Epoch 23/49, current lr=0.001\n",
            "train loss: 0.271498, val loss: 1.275987, accuracy: 70.43, time: 18.9877 min\n",
            "----------\n",
            "Epoch 24/49, current lr=0.001\n",
            "train loss: 0.261219, val loss: 1.165299, accuracy: 72.44, time: 19.7743 min\n",
            "----------\n",
            "Epoch 25/49, current lr=0.001\n",
            "train loss: 0.231446, val loss: 1.129314, accuracy: 72.67, time: 20.5619 min\n",
            "----------\n",
            "Epoch 26/49, current lr=0.001\n",
            "train loss: 0.246226, val loss: 1.224748, accuracy: 72.99, time: 21.3491 min\n",
            "----------\n",
            "Epoch 27/49, current lr=0.001\n",
            "train loss: 0.239895, val loss: 1.590895, accuracy: 67.65, time: 22.1373 min\n",
            "----------\n",
            "Epoch 28/49, current lr=0.001\n",
            "train loss: 0.187860, val loss: 1.303646, accuracy: 73.01, time: 22.9234 min\n",
            "----------\n",
            "Epoch 29/49, current lr=0.001\n",
            "train loss: 0.180479, val loss: 1.090555, accuracy: 74.41, time: 23.7110 min\n",
            "----------\n",
            "Epoch 30/49, current lr=0.0001\n",
            "train loss: 0.086876, val loss: 0.938545, accuracy: 77.61, time: 24.4978 min\n",
            "----------\n",
            "Epoch 31/49, current lr=0.0001\n",
            "train loss: 0.045486, val loss: 0.930878, accuracy: 78.45, time: 25.2845 min\n",
            "----------\n",
            "Epoch 32/49, current lr=0.0001\n",
            "train loss: 0.031705, val loss: 0.945620, accuracy: 78.38, time: 26.0716 min\n",
            "----------\n",
            "Epoch 33/49, current lr=0.0001\n",
            "train loss: 0.030119, val loss: 0.920034, accuracy: 78.51, time: 26.8591 min\n",
            "----------\n",
            "Epoch 34/49, current lr=0.0001\n",
            "train loss: 0.023901, val loss: 0.928991, accuracy: 78.53, time: 27.6463 min\n",
            "----------\n",
            "Epoch 35/49, current lr=0.0001\n",
            "train loss: 0.020153, val loss: 0.928867, accuracy: 78.72, time: 28.4338 min\n",
            "----------\n",
            "Epoch 36/49, current lr=0.0001\n",
            "train loss: 0.020980, val loss: 0.943976, accuracy: 78.70, time: 29.2200 min\n",
            "----------\n",
            "Epoch 37/49, current lr=0.0001\n",
            "train loss: 0.016101, val loss: 0.945922, accuracy: 78.53, time: 30.0059 min\n",
            "----------\n",
            "Epoch 38/49, current lr=0.0001\n",
            "train loss: 0.018018, val loss: 0.943887, accuracy: 78.51, time: 30.7939 min\n",
            "----------\n",
            "Epoch 39/49, current lr=0.0001\n",
            "train loss: 0.016992, val loss: 0.993977, accuracy: 78.21, time: 31.5812 min\n",
            "----------\n",
            "Epoch 40/49, current lr=0.0001\n",
            "train loss: 0.014672, val loss: 0.938372, accuracy: 78.59, time: 32.3677 min\n",
            "----------\n",
            "Epoch 41/49, current lr=0.0001\n",
            "train loss: 0.012919, val loss: 0.941630, accuracy: 78.46, time: 33.1558 min\n",
            "----------\n",
            "Epoch 42/49, current lr=0.0001\n",
            "train loss: 0.010199, val loss: 0.964515, accuracy: 78.69, time: 33.9431 min\n",
            "----------\n",
            "Epoch 43/49, current lr=0.0001\n",
            "train loss: 0.011596, val loss: 0.974373, accuracy: 78.45, time: 34.7296 min\n",
            "----------\n",
            "Epoch 44/49, current lr=0.0001\n",
            "train loss: 0.009768, val loss: 0.972592, accuracy: 78.83, time: 35.5161 min\n",
            "----------\n",
            "Epoch 45/49, current lr=0.0001\n",
            "train loss: 0.010535, val loss: 0.996988, accuracy: 78.46, time: 36.3031 min\n",
            "----------\n",
            "Epoch 46/49, current lr=0.0001\n",
            "train loss: 0.009129, val loss: 0.976950, accuracy: 78.72, time: 37.0929 min\n",
            "----------\n",
            "Epoch 47/49, current lr=0.0001\n",
            "train loss: 0.008946, val loss: 0.965577, accuracy: 78.74, time: 37.8771 min\n",
            "----------\n",
            "Epoch 48/49, current lr=0.0001\n",
            "train loss: 0.007069, val loss: 1.002556, accuracy: 78.51, time: 38.6630 min\n",
            "----------\n",
            "Epoch 49/49, current lr=0.0001\n",
            "train loss: 0.008383, val loss: 1.017118, accuracy: 78.27, time: 39.4477 min\n",
            "----------\n"
          ]
        }
      ]
    }
  ]
}