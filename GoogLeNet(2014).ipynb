{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogLeNet(2014).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01e36fa7b2fb47be9db8cd8e56b4cee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_127939226ece4bbca0020e648f6c84d8",
              "IPY_MODEL_a0e3b6df5a154c45b6c6614a9b16983d",
              "IPY_MODEL_55d40e3d6d2641d9ada097094faf9d7e"
            ],
            "layout": "IPY_MODEL_4101e172460b43448bf5f4c96c5fb600"
          }
        },
        "127939226ece4bbca0020e648f6c84d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a7795060114d08aa38fe022b9076a8",
            "placeholder": "​",
            "style": "IPY_MODEL_b3f3aa1224d6424bbca2a2709961e57e",
            "value": "100%"
          }
        },
        "a0e3b6df5a154c45b6c6614a9b16983d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f8b0ad3be2b4e2f969059b7dc30fc11",
            "max": 2640397119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0e74ee788b94bd3923f6909ba61d6b3",
            "value": 2640397119
          }
        },
        "55d40e3d6d2641d9ada097094faf9d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b299c75dfe448f6b25fb98bd9c3938c",
            "placeholder": "​",
            "style": "IPY_MODEL_3283babc96e0459b80c30281a9c30ece",
            "value": " 2640397119/2640397119 [04:43&lt;00:00, 59549946.80it/s]"
          }
        },
        "4101e172460b43448bf5f4c96c5fb600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a7795060114d08aa38fe022b9076a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f3aa1224d6424bbca2a2709961e57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f8b0ad3be2b4e2f969059b7dc30fc11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e74ee788b94bd3923f6909ba61d6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b299c75dfe448f6b25fb98bd9c3938c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3283babc96e0459b80c30281a9c30ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oc5lTLIo1LN3"
      },
      "outputs": [],
      "source": [
        "# 필요한 모듈을 import하기\n",
        "# 모델과 관련된 모듈 import하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# DataSet 및 DataLoader관련 모듈 import\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# 이미지 출력을 위한 모듈 import\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 기타 모듈 import하기\n",
        "import numpy as np\n",
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 학습과 평가에 STL Dataset을 이용할 것이다\n",
        "# STL Dataset를 저장할 Directory를 명시하도록 하자\n",
        "path2data = \"./data\"\n",
        "\n",
        "if not os.path.exists(path2data):\n",
        "  os.mkdir(path2data)\n",
        "\n",
        "# STL10 Dataset중 train_dataset loading\n",
        "# STL10 Dataset중 validation_dataset loading\n",
        "train_ds = datasets.STL10(path2data, split='train', download=True, transform=transforms.ToTensor())\n",
        "val_ds = datasets.STL10(path2data, split='test', download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "01e36fa7b2fb47be9db8cd8e56b4cee8",
            "127939226ece4bbca0020e648f6c84d8",
            "a0e3b6df5a154c45b6c6614a9b16983d",
            "55d40e3d6d2641d9ada097094faf9d7e",
            "4101e172460b43448bf5f4c96c5fb600",
            "65a7795060114d08aa38fe022b9076a8",
            "b3f3aa1224d6424bbca2a2709961e57e",
            "5f8b0ad3be2b4e2f969059b7dc30fc11",
            "a0e74ee788b94bd3923f6909ba61d6b3",
            "2b299c75dfe448f6b25fb98bd9c3938c",
            "3283babc96e0459b80c30281a9c30ece"
          ]
        },
        "id": "wGCKJfEQ1iRD",
        "outputId": "5a78f353-2f10-4987-d4b4-95cf9ed90c3f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2640397119 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01e36fa7b2fb47be9db8cd8e56b4cee8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset을 정규화하기 위하여 각 채널별 평균과 표준편차를 구한다\n",
        "# 우리가 직접 제작한 모델은 STL10 훈련 데이터에 익숙해진 모델이다\n",
        "# 모델이 익숙해하는 훈련 데이터와 같은 RGB로 모든 dataset를 정규화하여야 한다\n",
        "\n",
        "train_meanRGB = [np.mean(x.numpy(),axis=(1,2)) for x, _ in train_ds]\n",
        "train_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_ds]\n",
        "\n",
        "train_meanR = np.mean([m[0] for m in train_meanRGB])\n",
        "train_meanG = np.mean([m[1] for m in train_meanRGB])\n",
        "train_meanB = np.mean([m[2] for m in train_meanRGB])\n",
        "train_stdR = np.std([s[0] for s in train_stdRGB])\n",
        "train_stdG = np.std([s[1] for s in train_stdRGB])\n",
        "train_stdB = np.std([s[2] for s in train_stdRGB])\n",
        "\n",
        "val_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in val_ds]\n",
        "val_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in val_ds]\n",
        "\n",
        "val_meanR = np.mean([m[0] for m in val_meanRGB])\n",
        "val_meanG = np.mean([m[1] for m in val_meanRGB])\n",
        "val_meanB = np.mean([m[2] for m in val_meanRGB])\n",
        "std_meanR = np.std([s[0] for s in val_stdRGB])\n",
        "std_meanG = np.std([s[1] for s in val_stdRGB])\n",
        "std_meanB = np.std([s[2] for s in val_stdRGB])\n",
        "\n",
        "print(train_meanR, train_meanG, train_meanB)\n",
        "print(val_meanR, val_meanG, val_meanB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fZPEVw32bRT",
        "outputId": "5e408baa-9371-49c8-a48e-629bcff65836"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4467106 0.43980986 0.40664646\n",
            "0.44723064 0.4396425 0.40495726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset을 불러올 때 사용할 Preprocessor와 DataLoader를 정의하자\n",
        "train_transformation = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Resize(224),\n",
        "                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
        "                        transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "val_transformation = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Resize(224),\n",
        "                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB])                                      \n",
        "])\n",
        "train_ds.transform = train_transformation\n",
        "val_ds.transform = val_transformation\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "cx8Qx_-I4OYt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogLeNet 모델을 정의해보자\n",
        "# 가장 먼저 Channel Reduction Inception Module을 정의할 것인데,\n",
        "# 해당 Inception Module을 구성하는 각 branch에 삽입되는 합성곱층에 Batch normalization과 ReLU를 일괄적으로 적용하기 위하여\n",
        "# 다음과 같은 클래스를 정의하였다.\n",
        "\n",
        "# Convolution Layer의 여러 Parameter는 kwargs라는 이름의 파라미터로 받게 된다.\n",
        "class conv_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels,**kwargs):\n",
        "    super(conv_block, self).__init__()\n",
        "\n",
        "    self.conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, **kwargs),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv_layer(x)\n"
      ],
      "metadata": {
        "id": "Tuj59mxxjRZC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduced Dimension inception module을 정의한다\n",
        "# 각 parameter 설명\n",
        "# out_1x1 : 첫 번째 branch의 최종 출력 채널\n",
        "# red_3x3, out_3x3 : 두 번째 branch의 중간, 최종 출력 채널\n",
        "# red_5x5, out_5x5 : 세 번째 branch의 중간, 최종 출력 채널\n",
        "# out_1x1pool : 네 번째 branch의 최종 출력 채널\n",
        "\n",
        "class Inception_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
        "    super(Inception_block, self).__init__()\n",
        "\n",
        "    # GoogLeNet의 inception Module은 총 4개의 branch의 출력을 채널 방향으로 Concatanate한다\n",
        "    # 첫 번째 branch 정의하기\n",
        "    self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
        "\n",
        "    # 두 번째 branch 정의하기\n",
        "    # 각 branch의 padding은 출력 형상을 입력과 일치시키기 위해 설정한 것이다\n",
        "    self.branch2 = nn.Sequential(\n",
        "        conv_block(in_channels, red_3x3, kernel_size=1),\n",
        "        conv_block(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
        "    )\n",
        "\n",
        "    self.branch3 = nn.Sequential(\n",
        "        conv_block(in_channels, red_5x5, kernel_size=1),\n",
        "        conv_block(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
        "    )\n",
        "\n",
        "    self.branch4 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        conv_block(in_channels, out_1x1pool, kernel_size=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x의 차원은 (Batch_size, Channel, Width, Height)로 구성되어 있다\n",
        "    # 각 branch의 출력을 channel방향으로 concatenate하여 다음 Layer로 전달한다\n",
        "    x = torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)],1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "bDzpIO-glAZ5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogLeNet만의 특수한 구조 Auxiliary classifier\n",
        "# auxiliary classifier에 의한 학습 시 loss에는 0.3을 곱하여 영향을 최소화한다\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super(InceptionAux, self).__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.AvgPool2d(kernel_size=5, stride=3),\n",
        "        conv_block(in_channels, 128, kernel_size=1)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(2048,1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(1024, num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5zW-2SDMpPUZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogLeNet의 network in network에 사용되는 여러 모듈을 정의하였다\n",
        "# 이제 GoogLeNet을 정의해보자\n",
        "# aux_logits : 해당 GoogLeNet모델에 Auxiliary Classifier를 적용할지 여부를 선택한다\n",
        "# True이면 해당 모델 내에 Auxiliary Classifier를 설치한다\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "  def __init__(self, aux_logits=True, num_classes=10, init_weights=True):\n",
        "    super(GoogLeNet, self).__init__()\n",
        "\n",
        "    # aux_logits값이 True 또는 False이어야 한다\n",
        "    assert aux_logits == True or aux_logits == False\n",
        "    self.aux_logits = aux_logits\n",
        "\n",
        "    # GoogLeNet의 전체 Layer 정의하기\n",
        "    # Auxiliary Classifier는 inception 4b, 4e와 연결 되어있다\n",
        "    self.conv1 = conv_block(3,64,kernel_size=7, stride=2, padding=3)\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.conv2 = conv_block(64,192, kernel_size=3, stride=1, padding=1)\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "    self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "    self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "\n",
        "    self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "    self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "    self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "\n",
        "    self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128 )\n",
        "    self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "    self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    self.fc1 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    # GoogLeNet에 Auxiliary Classifier를 설정할지 여부에 따라 모델을 다르게 만든다\n",
        "    if self.aux_logits:\n",
        "      self.aux1 = InceptionAux(512, num_classes) # 입력채널 수가 Inception_4b와 같다\n",
        "      self.aux2 = InceptionAux(528, num_classes) # 입력채널 수가 Inception_4e와 같다\n",
        "    else :\n",
        "      self.aux1 = self.aux2 = None\n",
        "\n",
        "    # weight initialization\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.inception3a(x)\n",
        "    x = self.inception3b(x)\n",
        "    x = self.maxpool3(x)\n",
        "    x = self.inception4a(x)\n",
        "\n",
        "    # 만약 Auxiliary Classifier가 적용되어 있고, 학습 모드라면\n",
        "    # 첫 번째 Auxiliary Classifier의 결과를 저장한다\n",
        "\n",
        "    if self.aux_logits and self.training:\n",
        "      aux1 = self.aux1(x)\n",
        "\n",
        "    x = self.inception4b(x)\n",
        "    x = self.inception4c(x)\n",
        "    x = self.inception4d(x)\n",
        "\n",
        "    # 만약 Auxiliary Classifier가 적용되어 있고, 학습 모드라면\n",
        "    # 두 번째 Auxiliary Classifier의 결과를 저장한다\n",
        "    if self.aux_logits and self.training:\n",
        "        aux2 = self.aux2(x)\n",
        "\n",
        "    x = self.inception4e(x)\n",
        "    x = self.maxpool4(x)\n",
        "    x = self.inception5a(x)\n",
        "    x = self.inception5b(x)\n",
        "    x = self.avgpool(x)\n",
        "\n",
        "    x = x.view(x.shape[0], -1)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc1(x) # 실제 Classifier\n",
        "    \n",
        "    if self.aux_logits and self.training:\n",
        "      return (x, aux1, aux2)\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "  # GoogLeNet모델의 가중치를 초기화 해주는 인스턴스 함수를 정의한다\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        # 모델의 가중치를 초기화하는 함수 (다시 공부 필요)\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias,0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight,1)\n",
        "        nn.init.constant_(m.bias,0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.constant_(m.bias,0)\n"
      ],
      "metadata": {
        "id": "se4F7V-bsGHp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device를 정의 및 모델을 생성한다\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GoogLeNet(aux_logits=True, num_classes=10, init_weights=True).to(device)"
      ],
      "metadata": {
        "id": "HOnmaHE083q7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model이 올바르게 정의되었는지 확인하기 위하여 임의의 input을 통과시켜 보자\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cT70jZQ9xmZ",
        "outputId": "abcadc01-83d8-4d92-e7c5-790c0c6ee0a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.2895,  0.0457, -0.1783, -0.2039,  0.0130, -0.1233,  0.3969,  0.0162,\n",
            "          0.4104,  0.0854],\n",
            "        [-0.1566, -0.0955, -0.0685, -0.3567, -0.2379, -0.2134,  0.1932,  0.1632,\n",
            "          0.1996,  0.2858],\n",
            "        [-0.2644,  0.0648, -0.1727, -0.2735, -0.0195, -0.2080,  0.1898, -0.1888,\n",
            "          0.3746,  0.1370]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[ 0.0024,  0.0240, -0.0657, -0.0388,  0.0028, -0.2086, -0.0240, -0.0231,\n",
            "          0.0806, -0.0291],\n",
            "        [-0.0873, -0.1041,  0.1453, -0.2192,  0.0677,  0.0844,  0.1850,  0.0079,\n",
            "          0.0101, -0.0107],\n",
            "        [ 0.0461, -0.0172, -0.1114, -0.0248, -0.0499,  0.0195,  0.2063,  0.0542,\n",
            "         -0.0011, -0.0039]], device='cuda:0', grad_fn=<AddmmBackward0>), tensor([[-0.0401,  0.1737, -0.0432,  0.1349,  0.1508,  0.1586,  0.0778,  0.0447,\n",
            "         -0.0762, -0.0366],\n",
            "        [ 0.0152,  0.0393,  0.0213,  0.0286,  0.0226,  0.0627,  0.1484, -0.1787,\n",
            "         -0.0482,  0.0707],\n",
            "        [ 0.1294,  0.3205, -0.1958,  0.0854, -0.0760,  0.0307, -0.1650, -0.0857,\n",
            "         -0.1517,  0.1657]], device='cuda:0', grad_fn=<AddmmBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model을 print하여 전체 구조 파악\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62iNUp0z967j",
        "outputId": "62d8fd88-508a-4ae2-f718-0c71c446fc6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GoogLeNet(\n",
            "  (conv1): conv_block(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): conv_block(\n",
            "    (conv_layer): Sequential(\n",
            "      (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (inception3a): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception3b): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (inception4a): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4b): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4c): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4d): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4e): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (inception5a): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception5b): Inception_block(\n",
            "    (branch1): conv_block(\n",
            "      (conv_layer): Sequential(\n",
            "        (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  (aux1): InceptionAux(\n",
            "    (conv): Sequential(\n",
            "      (0): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (aux2): InceptionAux(\n",
            "    (conv): Sequential(\n",
            "      (0): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
            "      (1): conv_block(\n",
            "        (conv_layer): Sequential(\n",
            "          (0): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchsummary이용하여 임의의 입력값이 input되었을 때 어떠한 형태로 처리되는지 확인한다\n",
        "summary(model, input_size=(3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eam3Xsq2-GHC",
        "outputId": "e9336e1c-ebf2-48c8-da53-ddcea89016ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "        conv_block-4         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
            "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
            "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
            "              ReLU-8          [-1, 192, 56, 56]               0\n",
            "        conv_block-9          [-1, 192, 56, 56]               0\n",
            "        MaxPool2d-10          [-1, 192, 28, 28]               0\n",
            "           Conv2d-11           [-1, 64, 28, 28]          12,352\n",
            "      BatchNorm2d-12           [-1, 64, 28, 28]             128\n",
            "             ReLU-13           [-1, 64, 28, 28]               0\n",
            "       conv_block-14           [-1, 64, 28, 28]               0\n",
            "           Conv2d-15           [-1, 96, 28, 28]          18,528\n",
            "      BatchNorm2d-16           [-1, 96, 28, 28]             192\n",
            "             ReLU-17           [-1, 96, 28, 28]               0\n",
            "       conv_block-18           [-1, 96, 28, 28]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]         110,720\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "       conv_block-22          [-1, 128, 28, 28]               0\n",
            "           Conv2d-23           [-1, 16, 28, 28]           3,088\n",
            "      BatchNorm2d-24           [-1, 16, 28, 28]              32\n",
            "             ReLU-25           [-1, 16, 28, 28]               0\n",
            "       conv_block-26           [-1, 16, 28, 28]               0\n",
            "           Conv2d-27           [-1, 32, 28, 28]          12,832\n",
            "      BatchNorm2d-28           [-1, 32, 28, 28]              64\n",
            "             ReLU-29           [-1, 32, 28, 28]               0\n",
            "       conv_block-30           [-1, 32, 28, 28]               0\n",
            "        MaxPool2d-31          [-1, 192, 28, 28]               0\n",
            "           Conv2d-32           [-1, 32, 28, 28]           6,176\n",
            "      BatchNorm2d-33           [-1, 32, 28, 28]              64\n",
            "             ReLU-34           [-1, 32, 28, 28]               0\n",
            "       conv_block-35           [-1, 32, 28, 28]               0\n",
            "  Inception_block-36          [-1, 256, 28, 28]               0\n",
            "           Conv2d-37          [-1, 128, 28, 28]          32,896\n",
            "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
            "             ReLU-39          [-1, 128, 28, 28]               0\n",
            "       conv_block-40          [-1, 128, 28, 28]               0\n",
            "           Conv2d-41          [-1, 128, 28, 28]          32,896\n",
            "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
            "             ReLU-43          [-1, 128, 28, 28]               0\n",
            "       conv_block-44          [-1, 128, 28, 28]               0\n",
            "           Conv2d-45          [-1, 192, 28, 28]         221,376\n",
            "      BatchNorm2d-46          [-1, 192, 28, 28]             384\n",
            "             ReLU-47          [-1, 192, 28, 28]               0\n",
            "       conv_block-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49           [-1, 32, 28, 28]           8,224\n",
            "      BatchNorm2d-50           [-1, 32, 28, 28]              64\n",
            "             ReLU-51           [-1, 32, 28, 28]               0\n",
            "       conv_block-52           [-1, 32, 28, 28]               0\n",
            "           Conv2d-53           [-1, 96, 28, 28]          76,896\n",
            "      BatchNorm2d-54           [-1, 96, 28, 28]             192\n",
            "             ReLU-55           [-1, 96, 28, 28]               0\n",
            "       conv_block-56           [-1, 96, 28, 28]               0\n",
            "        MaxPool2d-57          [-1, 256, 28, 28]               0\n",
            "           Conv2d-58           [-1, 64, 28, 28]          16,448\n",
            "      BatchNorm2d-59           [-1, 64, 28, 28]             128\n",
            "             ReLU-60           [-1, 64, 28, 28]               0\n",
            "       conv_block-61           [-1, 64, 28, 28]               0\n",
            "  Inception_block-62          [-1, 480, 28, 28]               0\n",
            "        MaxPool2d-63          [-1, 480, 14, 14]               0\n",
            "           Conv2d-64          [-1, 192, 14, 14]          92,352\n",
            "      BatchNorm2d-65          [-1, 192, 14, 14]             384\n",
            "             ReLU-66          [-1, 192, 14, 14]               0\n",
            "       conv_block-67          [-1, 192, 14, 14]               0\n",
            "           Conv2d-68           [-1, 96, 14, 14]          46,176\n",
            "      BatchNorm2d-69           [-1, 96, 14, 14]             192\n",
            "             ReLU-70           [-1, 96, 14, 14]               0\n",
            "       conv_block-71           [-1, 96, 14, 14]               0\n",
            "           Conv2d-72          [-1, 208, 14, 14]         179,920\n",
            "      BatchNorm2d-73          [-1, 208, 14, 14]             416\n",
            "             ReLU-74          [-1, 208, 14, 14]               0\n",
            "       conv_block-75          [-1, 208, 14, 14]               0\n",
            "           Conv2d-76           [-1, 16, 14, 14]           7,696\n",
            "      BatchNorm2d-77           [-1, 16, 14, 14]              32\n",
            "             ReLU-78           [-1, 16, 14, 14]               0\n",
            "       conv_block-79           [-1, 16, 14, 14]               0\n",
            "           Conv2d-80           [-1, 48, 14, 14]          19,248\n",
            "      BatchNorm2d-81           [-1, 48, 14, 14]              96\n",
            "             ReLU-82           [-1, 48, 14, 14]               0\n",
            "       conv_block-83           [-1, 48, 14, 14]               0\n",
            "        MaxPool2d-84          [-1, 480, 14, 14]               0\n",
            "           Conv2d-85           [-1, 64, 14, 14]          30,784\n",
            "      BatchNorm2d-86           [-1, 64, 14, 14]             128\n",
            "             ReLU-87           [-1, 64, 14, 14]               0\n",
            "       conv_block-88           [-1, 64, 14, 14]               0\n",
            "  Inception_block-89          [-1, 512, 14, 14]               0\n",
            "        AvgPool2d-90            [-1, 512, 4, 4]               0\n",
            "           Conv2d-91            [-1, 128, 4, 4]          65,664\n",
            "      BatchNorm2d-92            [-1, 128, 4, 4]             256\n",
            "             ReLU-93            [-1, 128, 4, 4]               0\n",
            "       conv_block-94            [-1, 128, 4, 4]               0\n",
            "           Linear-95                 [-1, 1024]       2,098,176\n",
            "             ReLU-96                 [-1, 1024]               0\n",
            "          Dropout-97                 [-1, 1024]               0\n",
            "           Linear-98                   [-1, 10]          10,250\n",
            "     InceptionAux-99                   [-1, 10]               0\n",
            "          Conv2d-100          [-1, 160, 14, 14]          82,080\n",
            "     BatchNorm2d-101          [-1, 160, 14, 14]             320\n",
            "            ReLU-102          [-1, 160, 14, 14]               0\n",
            "      conv_block-103          [-1, 160, 14, 14]               0\n",
            "          Conv2d-104          [-1, 112, 14, 14]          57,456\n",
            "     BatchNorm2d-105          [-1, 112, 14, 14]             224\n",
            "            ReLU-106          [-1, 112, 14, 14]               0\n",
            "      conv_block-107          [-1, 112, 14, 14]               0\n",
            "          Conv2d-108          [-1, 224, 14, 14]         226,016\n",
            "     BatchNorm2d-109          [-1, 224, 14, 14]             448\n",
            "            ReLU-110          [-1, 224, 14, 14]               0\n",
            "      conv_block-111          [-1, 224, 14, 14]               0\n",
            "          Conv2d-112           [-1, 24, 14, 14]          12,312\n",
            "     BatchNorm2d-113           [-1, 24, 14, 14]              48\n",
            "            ReLU-114           [-1, 24, 14, 14]               0\n",
            "      conv_block-115           [-1, 24, 14, 14]               0\n",
            "          Conv2d-116           [-1, 64, 14, 14]          38,464\n",
            "     BatchNorm2d-117           [-1, 64, 14, 14]             128\n",
            "            ReLU-118           [-1, 64, 14, 14]               0\n",
            "      conv_block-119           [-1, 64, 14, 14]               0\n",
            "       MaxPool2d-120          [-1, 512, 14, 14]               0\n",
            "          Conv2d-121           [-1, 64, 14, 14]          32,832\n",
            "     BatchNorm2d-122           [-1, 64, 14, 14]             128\n",
            "            ReLU-123           [-1, 64, 14, 14]               0\n",
            "      conv_block-124           [-1, 64, 14, 14]               0\n",
            " Inception_block-125          [-1, 512, 14, 14]               0\n",
            "          Conv2d-126          [-1, 128, 14, 14]          65,664\n",
            "     BatchNorm2d-127          [-1, 128, 14, 14]             256\n",
            "            ReLU-128          [-1, 128, 14, 14]               0\n",
            "      conv_block-129          [-1, 128, 14, 14]               0\n",
            "          Conv2d-130          [-1, 128, 14, 14]          65,664\n",
            "     BatchNorm2d-131          [-1, 128, 14, 14]             256\n",
            "            ReLU-132          [-1, 128, 14, 14]               0\n",
            "      conv_block-133          [-1, 128, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         295,168\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "      conv_block-137          [-1, 256, 14, 14]               0\n",
            "          Conv2d-138           [-1, 24, 14, 14]          12,312\n",
            "     BatchNorm2d-139           [-1, 24, 14, 14]              48\n",
            "            ReLU-140           [-1, 24, 14, 14]               0\n",
            "      conv_block-141           [-1, 24, 14, 14]               0\n",
            "          Conv2d-142           [-1, 64, 14, 14]          38,464\n",
            "     BatchNorm2d-143           [-1, 64, 14, 14]             128\n",
            "            ReLU-144           [-1, 64, 14, 14]               0\n",
            "      conv_block-145           [-1, 64, 14, 14]               0\n",
            "       MaxPool2d-146          [-1, 512, 14, 14]               0\n",
            "          Conv2d-147           [-1, 64, 14, 14]          32,832\n",
            "     BatchNorm2d-148           [-1, 64, 14, 14]             128\n",
            "            ReLU-149           [-1, 64, 14, 14]               0\n",
            "      conv_block-150           [-1, 64, 14, 14]               0\n",
            " Inception_block-151          [-1, 512, 14, 14]               0\n",
            "          Conv2d-152          [-1, 112, 14, 14]          57,456\n",
            "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
            "            ReLU-154          [-1, 112, 14, 14]               0\n",
            "      conv_block-155          [-1, 112, 14, 14]               0\n",
            "          Conv2d-156          [-1, 144, 14, 14]          73,872\n",
            "     BatchNorm2d-157          [-1, 144, 14, 14]             288\n",
            "            ReLU-158          [-1, 144, 14, 14]               0\n",
            "      conv_block-159          [-1, 144, 14, 14]               0\n",
            "          Conv2d-160          [-1, 288, 14, 14]         373,536\n",
            "     BatchNorm2d-161          [-1, 288, 14, 14]             576\n",
            "            ReLU-162          [-1, 288, 14, 14]               0\n",
            "      conv_block-163          [-1, 288, 14, 14]               0\n",
            "          Conv2d-164           [-1, 32, 14, 14]          16,416\n",
            "     BatchNorm2d-165           [-1, 32, 14, 14]              64\n",
            "            ReLU-166           [-1, 32, 14, 14]               0\n",
            "      conv_block-167           [-1, 32, 14, 14]               0\n",
            "          Conv2d-168           [-1, 64, 14, 14]          51,264\n",
            "     BatchNorm2d-169           [-1, 64, 14, 14]             128\n",
            "            ReLU-170           [-1, 64, 14, 14]               0\n",
            "      conv_block-171           [-1, 64, 14, 14]               0\n",
            "       MaxPool2d-172          [-1, 512, 14, 14]               0\n",
            "          Conv2d-173           [-1, 64, 14, 14]          32,832\n",
            "     BatchNorm2d-174           [-1, 64, 14, 14]             128\n",
            "            ReLU-175           [-1, 64, 14, 14]               0\n",
            "      conv_block-176           [-1, 64, 14, 14]               0\n",
            " Inception_block-177          [-1, 528, 14, 14]               0\n",
            "       AvgPool2d-178            [-1, 528, 4, 4]               0\n",
            "          Conv2d-179            [-1, 128, 4, 4]          67,712\n",
            "     BatchNorm2d-180            [-1, 128, 4, 4]             256\n",
            "            ReLU-181            [-1, 128, 4, 4]               0\n",
            "      conv_block-182            [-1, 128, 4, 4]               0\n",
            "          Linear-183                 [-1, 1024]       2,098,176\n",
            "            ReLU-184                 [-1, 1024]               0\n",
            "         Dropout-185                 [-1, 1024]               0\n",
            "          Linear-186                   [-1, 10]          10,250\n",
            "    InceptionAux-187                   [-1, 10]               0\n",
            "          Conv2d-188          [-1, 256, 14, 14]         135,424\n",
            "     BatchNorm2d-189          [-1, 256, 14, 14]             512\n",
            "            ReLU-190          [-1, 256, 14, 14]               0\n",
            "      conv_block-191          [-1, 256, 14, 14]               0\n",
            "          Conv2d-192          [-1, 160, 14, 14]          84,640\n",
            "     BatchNorm2d-193          [-1, 160, 14, 14]             320\n",
            "            ReLU-194          [-1, 160, 14, 14]               0\n",
            "      conv_block-195          [-1, 160, 14, 14]               0\n",
            "          Conv2d-196          [-1, 320, 14, 14]         461,120\n",
            "     BatchNorm2d-197          [-1, 320, 14, 14]             640\n",
            "            ReLU-198          [-1, 320, 14, 14]               0\n",
            "      conv_block-199          [-1, 320, 14, 14]               0\n",
            "          Conv2d-200           [-1, 32, 14, 14]          16,928\n",
            "     BatchNorm2d-201           [-1, 32, 14, 14]              64\n",
            "            ReLU-202           [-1, 32, 14, 14]               0\n",
            "      conv_block-203           [-1, 32, 14, 14]               0\n",
            "          Conv2d-204          [-1, 128, 14, 14]         102,528\n",
            "     BatchNorm2d-205          [-1, 128, 14, 14]             256\n",
            "            ReLU-206          [-1, 128, 14, 14]               0\n",
            "      conv_block-207          [-1, 128, 14, 14]               0\n",
            "       MaxPool2d-208          [-1, 528, 14, 14]               0\n",
            "          Conv2d-209          [-1, 128, 14, 14]          67,712\n",
            "     BatchNorm2d-210          [-1, 128, 14, 14]             256\n",
            "            ReLU-211          [-1, 128, 14, 14]               0\n",
            "      conv_block-212          [-1, 128, 14, 14]               0\n",
            " Inception_block-213          [-1, 832, 14, 14]               0\n",
            "       MaxPool2d-214            [-1, 832, 7, 7]               0\n",
            "          Conv2d-215            [-1, 256, 7, 7]         213,248\n",
            "     BatchNorm2d-216            [-1, 256, 7, 7]             512\n",
            "            ReLU-217            [-1, 256, 7, 7]               0\n",
            "      conv_block-218            [-1, 256, 7, 7]               0\n",
            "          Conv2d-219            [-1, 160, 7, 7]         133,280\n",
            "     BatchNorm2d-220            [-1, 160, 7, 7]             320\n",
            "            ReLU-221            [-1, 160, 7, 7]               0\n",
            "      conv_block-222            [-1, 160, 7, 7]               0\n",
            "          Conv2d-223            [-1, 320, 7, 7]         461,120\n",
            "     BatchNorm2d-224            [-1, 320, 7, 7]             640\n",
            "            ReLU-225            [-1, 320, 7, 7]               0\n",
            "      conv_block-226            [-1, 320, 7, 7]               0\n",
            "          Conv2d-227             [-1, 32, 7, 7]          26,656\n",
            "     BatchNorm2d-228             [-1, 32, 7, 7]              64\n",
            "            ReLU-229             [-1, 32, 7, 7]               0\n",
            "      conv_block-230             [-1, 32, 7, 7]               0\n",
            "          Conv2d-231            [-1, 128, 7, 7]         102,528\n",
            "     BatchNorm2d-232            [-1, 128, 7, 7]             256\n",
            "            ReLU-233            [-1, 128, 7, 7]               0\n",
            "      conv_block-234            [-1, 128, 7, 7]               0\n",
            "       MaxPool2d-235            [-1, 832, 7, 7]               0\n",
            "          Conv2d-236            [-1, 128, 7, 7]         106,624\n",
            "     BatchNorm2d-237            [-1, 128, 7, 7]             256\n",
            "            ReLU-238            [-1, 128, 7, 7]               0\n",
            "      conv_block-239            [-1, 128, 7, 7]               0\n",
            " Inception_block-240            [-1, 832, 7, 7]               0\n",
            "          Conv2d-241            [-1, 384, 7, 7]         319,872\n",
            "     BatchNorm2d-242            [-1, 384, 7, 7]             768\n",
            "            ReLU-243            [-1, 384, 7, 7]               0\n",
            "      conv_block-244            [-1, 384, 7, 7]               0\n",
            "          Conv2d-245            [-1, 192, 7, 7]         159,936\n",
            "     BatchNorm2d-246            [-1, 192, 7, 7]             384\n",
            "            ReLU-247            [-1, 192, 7, 7]               0\n",
            "      conv_block-248            [-1, 192, 7, 7]               0\n",
            "          Conv2d-249            [-1, 384, 7, 7]         663,936\n",
            "     BatchNorm2d-250            [-1, 384, 7, 7]             768\n",
            "            ReLU-251            [-1, 384, 7, 7]               0\n",
            "      conv_block-252            [-1, 384, 7, 7]               0\n",
            "          Conv2d-253             [-1, 48, 7, 7]          39,984\n",
            "     BatchNorm2d-254             [-1, 48, 7, 7]              96\n",
            "            ReLU-255             [-1, 48, 7, 7]               0\n",
            "      conv_block-256             [-1, 48, 7, 7]               0\n",
            "          Conv2d-257            [-1, 128, 7, 7]         153,728\n",
            "     BatchNorm2d-258            [-1, 128, 7, 7]             256\n",
            "            ReLU-259            [-1, 128, 7, 7]               0\n",
            "      conv_block-260            [-1, 128, 7, 7]               0\n",
            "       MaxPool2d-261            [-1, 832, 7, 7]               0\n",
            "          Conv2d-262            [-1, 128, 7, 7]         106,624\n",
            "     BatchNorm2d-263            [-1, 128, 7, 7]             256\n",
            "            ReLU-264            [-1, 128, 7, 7]               0\n",
            "      conv_block-265            [-1, 128, 7, 7]               0\n",
            " Inception_block-266           [-1, 1024, 7, 7]               0\n",
            "       AvgPool2d-267           [-1, 1024, 1, 1]               0\n",
            "         Dropout-268                 [-1, 1024]               0\n",
            "          Linear-269                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 10,344,814\n",
            "Trainable params: 10,344,814\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 112.89\n",
            "Params size (MB): 39.46\n",
            "Estimated Total Size (MB): 152.92\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 본격적으로 학습을 위한 함수를 제작하자\n",
        "# 하나의 batch_set의 데이터들의 손실함수가 모두 합산되어 반환되도록 정의\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "# 30회마다 Learning rate를 10분의 1로 줄여주는 Scheduler 제작\n",
        "lr_scheduler = StepLR(opt, step_size=30, gamma=0.1)\n",
        "\n",
        "# optimizer의 현재 Learning rate를 반환하는 함수 제작\n",
        "def get_lr(opt):\n",
        "  return opt.param_groups[0]['lr']\n",
        "\n",
        "# model의 예측과 정답 label을 비교하여 맞춘 개수를 반환한다\n",
        "def metric_batch(output, target):\n",
        "  pred = output.argmax(dim=1, keepdim=True)\n",
        "  corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "  return corrects\n",
        "\n",
        "# batct학습 시 손실함수 이용하여 backpropagation을 하고 나서\n",
        "# 해당 batch의 총 loss값과 맞은 정답의 개수를 반환하는 함수\n",
        "\n",
        "def loss_batch(loss_func, outputs, target, opt=None):\n",
        "  # 만약 Auxiliary Classifier가 적용된 모델이 반환한 값이라면\n",
        "  # Main Classifier의 반환값, Aux. classifier 1,2의 반환값이 return된다\n",
        "  if len(outputs) == 3:\n",
        "    output, aux1, aux2 = outputs\n",
        "  \n",
        "    output_loss = loss_func(output, target)\n",
        "    aux1_loss = loss_func(aux1, target)\n",
        "    aux2_loss = loss_func(aux2, target)\n",
        "\n",
        "    # Aux. Classifier의 loss는 0.3을 곱하여 전체 loss에 더한다\n",
        "    loss = output_loss + 0.3*(aux1_loss + aux2_loss)\n",
        "\n",
        "    # 해당 batch_dataset에서 model이 맞춘 정답의 개수\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "  else:\n",
        "    loss = loss_func(outputs, target)\n",
        "    metric_b = metric_batch(outputs, target)\n",
        "\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "  return loss.item(), metric_b\n",
        "\n",
        "# 해당 dataloader를 이용해 model을 1 epoch 훈련시키고\n",
        "# 1epoch동안의 평균 손실함수값과 정확도를 반환하는 함수\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "  # epoch 동안의 평균 손실함수값\n",
        "  # epoch 동안의 평균 Precision 저장을 위한 변수 생성\n",
        "  running_loss = 0.0\n",
        "  running_metric = 0.0\n",
        "  len_data = len(dataset_dl.dataset)\n",
        "\n",
        "  for xb, yb in dataset_dl:\n",
        "    xb, yb = xb.to(device), yb.to(device)\n",
        "    output = model(xb)\n",
        "\n",
        "    loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "    running_loss += loss_b\n",
        "\n",
        "    if metric_b is not None:\n",
        "      running_metric += metric_b\n",
        "\n",
        "    if sanity_check is True:\n",
        "      break\n",
        "\n",
        "  loss = running_loss  / len_data\n",
        "  metric = running_metric / len_data\n",
        "\n",
        "  return loss, metric\n",
        "\n",
        "# configuration parameter를 params라는 인자로 전달하면\n",
        "# 해당 config에 맞게 Train을 해주는 함수를 정의하였다\n",
        "def train_val(model, params):\n",
        "  num_epochs=params[\"num_epochs\"]\n",
        "  loss_func=params[\"loss_func\"]\n",
        "  opt=params[\"optimizer\"]\n",
        "  train_dl=params[\"train_dl\"]\n",
        "  val_dl=params[\"val_dl\"]\n",
        "  sanity_check=params[\"sanity_check\"]\n",
        "  lr_scheduler=params[\"lr_scheduler\"]\n",
        "  path2weights=params[\"path2weights\"]\n",
        "\n",
        "  # epoch별 평균 loss와 정확도를 저장\n",
        "  loss_history = {'train':[], 'val':[]}\n",
        "  metric_history = {'train':[], 'val':[]}\n",
        "\n",
        "  # 가장 작은 손실함수값을 반환하는 모델의 가중치를 저장한다\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = float('inf')\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr)) \n",
        "\n",
        "    # 학습 모드\n",
        "    model.train()\n",
        "    # train_dataset 1 Epoch 훈련\n",
        "    train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "    \n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # 모델의 성능 평가모드\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      torch.save(model.state_dict(), path2weights)\n",
        "      print(\"Copied best model weights!\")\n",
        "\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)\n",
        "\n",
        "  # 학습을 모두 마치기 전 가장 손실함수가 적게 반환된 가중치로 모델을 초기화한다\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model, loss_history, metric_history\n",
        "\n"
      ],
      "metadata": {
        "id": "agiJc6kD_pH1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습함수의 configuration으로 적용할 parameter를 만든다\n",
        "params_train = {\n",
        "    'num_epochs':100,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# best_weights를 저장할 디렉토리를 생성한다\n",
        "def createFolder(dir_path):\n",
        "  try:\n",
        "    if not os.path.exists(dir_path):\n",
        "      os.makedirs(dir_path)\n",
        "  except OSerror:\n",
        "    print(\"Error\")\n",
        "createFolder(\"./models\")"
      ],
      "metadata": {
        "id": "AW-qMdEpFjhM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "id": "Bwi3OQ9BI-CD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}