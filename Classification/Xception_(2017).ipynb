{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception_(2017).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bbbb8ed8a2134e7eb1dd982c31e0bed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81e6b12faa004844aa01045a2427fa66",
              "IPY_MODEL_e8691b1910464ce6aad8546256c85095",
              "IPY_MODEL_24b6701fa34f44109b4c638fb389a02f"
            ],
            "layout": "IPY_MODEL_2e19b67023394e39ad6395c93c5a57fc"
          }
        },
        "81e6b12faa004844aa01045a2427fa66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850a827447824c11b3e4b343dbf49262",
            "placeholder": "​",
            "style": "IPY_MODEL_c69d787ecde24b6c858d89f96d327d31",
            "value": "100%"
          }
        },
        "e8691b1910464ce6aad8546256c85095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b61353c0379844c3adf5ffa817c2e69d",
            "max": 2640397119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69fefa43da14476db6e6eaaaff088e34",
            "value": 2640397119
          }
        },
        "24b6701fa34f44109b4c638fb389a02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8989b71368e485a9bd238b0ceb5b5bb",
            "placeholder": "​",
            "style": "IPY_MODEL_4f0c11b6e4f9476c9ebe51c03338db25",
            "value": " 2640397119/2640397119 [00:47&lt;00:00, 58471551.60it/s]"
          }
        },
        "2e19b67023394e39ad6395c93c5a57fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850a827447824c11b3e4b343dbf49262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69d787ecde24b6c858d89f96d327d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b61353c0379844c3adf5ffa817c2e69d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69fefa43da14476db6e6eaaaff088e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8989b71368e485a9bd238b0ceb5b5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f0c11b6e4f9476c9ebe51c03338db25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GjosuQ2-_Hct"
      },
      "outputs": [],
      "source": [
        "# 필요한 모듈 불러오기\n",
        "\n",
        "# model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "\n",
        "# dataset and transformation\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# display images\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# utils\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 본 모델의 학습과 성능평가를 위해 STL10 Dataset을 사용할 예정이다\n",
        "\n",
        "# STL Dataset을 다운로드 받을 Directory를 지정한다\n",
        "path2data = './data'\n",
        "\n",
        "# if not exists the path, make the directory\n",
        "if not os.path.exists(path2data):\n",
        "    os.mkdir(path2data)\n",
        "\n",
        "# load dataset\n",
        "train_ds = datasets.STL10(path2data, split='train', download=True, transform=transforms.ToTensor())\n",
        "val_ds = datasets.STL10(path2data, split='test', download=True, transform=transforms.ToTensor())\n",
        "\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "bbbb8ed8a2134e7eb1dd982c31e0bed1",
            "81e6b12faa004844aa01045a2427fa66",
            "e8691b1910464ce6aad8546256c85095",
            "24b6701fa34f44109b4c638fb389a02f",
            "2e19b67023394e39ad6395c93c5a57fc",
            "850a827447824c11b3e4b343dbf49262",
            "c69d787ecde24b6c858d89f96d327d31",
            "b61353c0379844c3adf5ffa817c2e69d",
            "69fefa43da14476db6e6eaaaff088e34",
            "d8989b71368e485a9bd238b0ceb5b5bb",
            "4f0c11b6e4f9476c9ebe51c03338db25"
          ]
        },
        "id": "wj5a6SLK_QOx",
        "outputId": "2c8b6fc0-ec03-4d1b-b9eb-b66d6e4c1e09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2640397119 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbbb8ed8a2134e7eb1dd982c31e0bed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "5000\n",
            "8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader에 사용될 Pre-Processor를 정의한다\n",
        "transformation = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Resize(299)\n",
        "])\n",
        "\n",
        "train_ds.transform = transformation\n",
        "val_ds.transform = transformation\n",
        "\n",
        "# Train dataset, Validation dataset의 Dataloader 생성\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "3YA5AXbHwqfL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xception 모델 구축에 필요한 여러 모듈을 구현해보자\n",
        "# Xception model은 Entry flow - Middle flow - Exit flow 크게 세 부분으로 구성된다\n",
        "# 여러 곳에 사용되는 블록인 Separable Convolution Layer을 먼저 구현해보자\n",
        "\n",
        "# 3x3 conv와 1x1 conv로 이루어져 있으며\n",
        "# 해당 Separable Conv layer를 통과하면 형상은 변화 없고 채널만 in_channel에서 out_channel로 변화한다\n",
        "class SeparableConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.separable = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.separable(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "CLE_BkQM_phh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entry flow를 정의하자\n",
        "class EntryFlow(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3,32,kernel_size=3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,64,kernel_size=3, stride=1, padding=0, bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()        \n",
        "    )\n",
        "\n",
        "    self.conv2_residual = nn.Sequential(\n",
        "        SeparableConv(64,128),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        SeparableConv(128,128),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)                    \n",
        "    )\n",
        "\n",
        "    self.conv2_shortcut = nn.Sequential(\n",
        "        nn.Conv2d(64,128, kernel_size=1, stride=2, padding=0),\n",
        "        nn.BatchNorm2d(128)\n",
        "    )\n",
        "\n",
        "    self.conv3_residual = nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        SeparableConv(128,256),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        SeparableConv(256,256),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    )\n",
        "\n",
        "    self.conv3_shortcut = nn.Sequential(\n",
        "        nn.Conv2d(128,256,kernel_size=1, stride=2, padding=0),\n",
        "        nn.BatchNorm2d(256)\n",
        "    )\n",
        "\n",
        "    self.conv4_residual = nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        SeparableConv(256,728),\n",
        "        nn.BatchNorm2d(728),\n",
        "        nn.ReLU(),\n",
        "        SeparableConv(728,728),\n",
        "        nn.BatchNorm2d(728),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)      \n",
        "    )\n",
        "\n",
        "    self.conv4_shortcut = nn.Sequential(\n",
        "        nn.Conv2d(256,728,kernel_size=1, stride=2, padding=0),\n",
        "        nn.BatchNorm2d(728)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2_residual(x) + self.conv2_shortcut(x)\n",
        "    x = self.conv3_residual(x) + self.conv3_shortcut(x)\n",
        "    x = self.conv4_residual(x) + self.conv4_shortcut(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "IStCOEINYl-E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MiddleFlow를 정의한다\n",
        "class MiddleFlow(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_residual = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            SeparableConv(728, 728),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv(728, 728),\n",
        "            nn.BatchNorm2d(728),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv(728, 728),\n",
        "            nn.BatchNorm2d(728)\n",
        "        )\n",
        "\n",
        "        self.conv_shortcut = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv_shortcut(x) + self.conv_residual(x)"
      ],
      "metadata": {
        "id": "CQarMC_ubGiq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ExitFlow를 정의한다\n",
        "class ExitFlow(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1_residual = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            SeparableConv(728, 1024),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv(1024, 1024),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv1_shortcut = nn.Sequential(\n",
        "            nn.Conv2d(728, 1024, 1, stride=2, padding=0),\n",
        "            nn.BatchNorm2d(1024)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            SeparableConv(1024, 1536),\n",
        "            nn.BatchNorm2d(1536),\n",
        "            nn.ReLU(),\n",
        "            SeparableConv(1536, 2048),\n",
        "            nn.BatchNorm2d(2048),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1_residual(x) + self.conv1_shortcut(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.avg_pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NeJILQmHbVOz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xception에 사용되는 모든 module을 정의하였다\n",
        "# 본격적으로 Xception 모듈을 정의해보자\n",
        "# Middle flow같은 경우는 _make_middle_flow라는 함수를 만들어 총 8개의 middle을 생성하였다\n",
        "\n",
        "class Xception(nn.Module):\n",
        "  def __init__(self, num_classes=10, init_weights=True):\n",
        "    super().__init__()\n",
        "    self.init_weights = init_weights\n",
        "\n",
        "    self.entry = EntryFlow()\n",
        "    self.middle = self._make_middle_flow()\n",
        "    self.exit = ExitFlow()\n",
        "\n",
        "    self.linear = nn.Linear(2048, num_classes)\n",
        "\n",
        "    if self.init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.entry(x)\n",
        "    x = self.middle(x)\n",
        "    x = self.exit(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "  def _make_middle_flow(self):\n",
        "    middle = nn.Sequential()\n",
        "    for i in range(8):\n",
        "      middle.add_module(\"middle_block_{}\".format(i), MiddleFlow())\n",
        "    return middle\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "      for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "              nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "              if m.bias is not None:\n",
        "                  nn.init.constant_(m.bias, 0)\n",
        "          elif isinstance(m, nn.BatchNorm2d):\n",
        "              nn.init.constant_(m.weight, 1)\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "          elif isinstance(m, nn.Linear):\n",
        "              nn.init.normal_(m.weight, 0, 0.01)\n",
        "              nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "a06ow8fmbhus"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 생성하고 Test input을 넣어 output을 확인해보자\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = torch.randn(3,3,299,299).to(device)\n",
        "model = Xception().to(device)\n",
        "output=model(x)\n",
        "print(\"output size : \", output.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsE0nCq6dNXs",
        "outputId": "64f5256d-5f78-4b70-a497-0ae1fc3c08ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output size :  torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 입력값에 대한 각 계층에서의 출력 확인\n",
        "summary(model, (3, 299, 299), device=device.type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOHwmviCeRPt",
        "outputId": "8bb8c451-8774-4fed-eb61-de62cc05b7d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 299, 299]             864\n",
            "       BatchNorm2d-2         [-1, 32, 299, 299]              64\n",
            "              ReLU-3         [-1, 32, 299, 299]               0\n",
            "            Conv2d-4         [-1, 64, 297, 297]          18,432\n",
            "       BatchNorm2d-5         [-1, 64, 297, 297]             128\n",
            "              ReLU-6         [-1, 64, 297, 297]               0\n",
            "            Conv2d-7         [-1, 64, 297, 297]          36,864\n",
            "            Conv2d-8        [-1, 128, 297, 297]           8,192\n",
            "     SeparableConv-9        [-1, 128, 297, 297]               0\n",
            "      BatchNorm2d-10        [-1, 128, 297, 297]             256\n",
            "             ReLU-11        [-1, 128, 297, 297]               0\n",
            "           Conv2d-12        [-1, 128, 297, 297]         147,456\n",
            "           Conv2d-13        [-1, 128, 297, 297]          16,384\n",
            "    SeparableConv-14        [-1, 128, 297, 297]               0\n",
            "      BatchNorm2d-15        [-1, 128, 297, 297]             256\n",
            "        MaxPool2d-16        [-1, 128, 149, 149]               0\n",
            "           Conv2d-17        [-1, 128, 149, 149]           8,320\n",
            "      BatchNorm2d-18        [-1, 128, 149, 149]             256\n",
            "             ReLU-19        [-1, 128, 149, 149]               0\n",
            "           Conv2d-20        [-1, 128, 149, 149]         147,456\n",
            "           Conv2d-21        [-1, 256, 149, 149]          32,768\n",
            "    SeparableConv-22        [-1, 256, 149, 149]               0\n",
            "      BatchNorm2d-23        [-1, 256, 149, 149]             512\n",
            "             ReLU-24        [-1, 256, 149, 149]               0\n",
            "           Conv2d-25        [-1, 256, 149, 149]         589,824\n",
            "           Conv2d-26        [-1, 256, 149, 149]          65,536\n",
            "    SeparableConv-27        [-1, 256, 149, 149]               0\n",
            "      BatchNorm2d-28        [-1, 256, 149, 149]             512\n",
            "        MaxPool2d-29          [-1, 256, 75, 75]               0\n",
            "           Conv2d-30          [-1, 256, 75, 75]          33,024\n",
            "      BatchNorm2d-31          [-1, 256, 75, 75]             512\n",
            "             ReLU-32          [-1, 256, 75, 75]               0\n",
            "           Conv2d-33          [-1, 256, 75, 75]         589,824\n",
            "           Conv2d-34          [-1, 728, 75, 75]         186,368\n",
            "    SeparableConv-35          [-1, 728, 75, 75]               0\n",
            "      BatchNorm2d-36          [-1, 728, 75, 75]           1,456\n",
            "             ReLU-37          [-1, 728, 75, 75]               0\n",
            "           Conv2d-38          [-1, 728, 75, 75]       4,769,856\n",
            "           Conv2d-39          [-1, 728, 75, 75]         529,984\n",
            "    SeparableConv-40          [-1, 728, 75, 75]               0\n",
            "      BatchNorm2d-41          [-1, 728, 75, 75]           1,456\n",
            "        MaxPool2d-42          [-1, 728, 38, 38]               0\n",
            "           Conv2d-43          [-1, 728, 38, 38]         187,096\n",
            "      BatchNorm2d-44          [-1, 728, 38, 38]           1,456\n",
            "        EntryFlow-45          [-1, 728, 38, 38]               0\n",
            "             ReLU-46          [-1, 728, 38, 38]               0\n",
            "           Conv2d-47          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-48          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-49          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-50          [-1, 728, 38, 38]           1,456\n",
            "             ReLU-51          [-1, 728, 38, 38]               0\n",
            "           Conv2d-52          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-53          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-54          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-55          [-1, 728, 38, 38]           1,456\n",
            "             ReLU-56          [-1, 728, 38, 38]               0\n",
            "           Conv2d-57          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-58          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-59          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-60          [-1, 728, 38, 38]           1,456\n",
            "       MiddleFlow-61          [-1, 728, 38, 38]               0\n",
            "             ReLU-62          [-1, 728, 38, 38]               0\n",
            "           Conv2d-63          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-64          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-65          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-66          [-1, 728, 38, 38]           1,456\n",
            "             ReLU-67          [-1, 728, 38, 38]               0\n",
            "           Conv2d-68          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-69          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-70          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-71          [-1, 728, 38, 38]           1,456\n",
            "             ReLU-72          [-1, 728, 38, 38]               0\n",
            "           Conv2d-73          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-74          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-75          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-76          [-1, 728, 38, 38]           1,456\n",
            "       MiddleFlow-77          [-1, 728, 38, 38]               0\n",
            "             ReLU-78          [-1, 728, 38, 38]               0\n",
            "           Conv2d-79          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-80          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-81          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-82          [-1, 728, 38, 38]           1,456\n",
            "             ReLU-83          [-1, 728, 38, 38]               0\n",
            "           Conv2d-84          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-85          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-86          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-87          [-1, 728, 38, 38]           1,456\n",
            "             ReLU-88          [-1, 728, 38, 38]               0\n",
            "           Conv2d-89          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-90          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-91          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-92          [-1, 728, 38, 38]           1,456\n",
            "       MiddleFlow-93          [-1, 728, 38, 38]               0\n",
            "             ReLU-94          [-1, 728, 38, 38]               0\n",
            "           Conv2d-95          [-1, 728, 38, 38]       4,769,856\n",
            "           Conv2d-96          [-1, 728, 38, 38]         529,984\n",
            "    SeparableConv-97          [-1, 728, 38, 38]               0\n",
            "      BatchNorm2d-98          [-1, 728, 38, 38]           1,456\n",
            "             ReLU-99          [-1, 728, 38, 38]               0\n",
            "          Conv2d-100          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-101          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-102          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-103          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-104          [-1, 728, 38, 38]               0\n",
            "          Conv2d-105          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-106          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-107          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-108          [-1, 728, 38, 38]           1,456\n",
            "      MiddleFlow-109          [-1, 728, 38, 38]               0\n",
            "            ReLU-110          [-1, 728, 38, 38]               0\n",
            "          Conv2d-111          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-112          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-113          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-114          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-115          [-1, 728, 38, 38]               0\n",
            "          Conv2d-116          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-117          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-118          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-119          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-120          [-1, 728, 38, 38]               0\n",
            "          Conv2d-121          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-122          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-123          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-124          [-1, 728, 38, 38]           1,456\n",
            "      MiddleFlow-125          [-1, 728, 38, 38]               0\n",
            "            ReLU-126          [-1, 728, 38, 38]               0\n",
            "          Conv2d-127          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-128          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-129          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-130          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-131          [-1, 728, 38, 38]               0\n",
            "          Conv2d-132          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-133          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-134          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-135          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-136          [-1, 728, 38, 38]               0\n",
            "          Conv2d-137          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-138          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-139          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-140          [-1, 728, 38, 38]           1,456\n",
            "      MiddleFlow-141          [-1, 728, 38, 38]               0\n",
            "            ReLU-142          [-1, 728, 38, 38]               0\n",
            "          Conv2d-143          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-144          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-145          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-146          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-147          [-1, 728, 38, 38]               0\n",
            "          Conv2d-148          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-149          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-150          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-151          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-152          [-1, 728, 38, 38]               0\n",
            "          Conv2d-153          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-154          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-155          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-156          [-1, 728, 38, 38]           1,456\n",
            "      MiddleFlow-157          [-1, 728, 38, 38]               0\n",
            "            ReLU-158          [-1, 728, 38, 38]               0\n",
            "          Conv2d-159          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-160          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-161          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-162          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-163          [-1, 728, 38, 38]               0\n",
            "          Conv2d-164          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-165          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-166          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-167          [-1, 728, 38, 38]           1,456\n",
            "            ReLU-168          [-1, 728, 38, 38]               0\n",
            "          Conv2d-169          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-170          [-1, 728, 38, 38]         529,984\n",
            "   SeparableConv-171          [-1, 728, 38, 38]               0\n",
            "     BatchNorm2d-172          [-1, 728, 38, 38]           1,456\n",
            "      MiddleFlow-173          [-1, 728, 38, 38]               0\n",
            "            ReLU-174          [-1, 728, 38, 38]               0\n",
            "          Conv2d-175          [-1, 728, 38, 38]       4,769,856\n",
            "          Conv2d-176         [-1, 1024, 38, 38]         745,472\n",
            "   SeparableConv-177         [-1, 1024, 38, 38]               0\n",
            "     BatchNorm2d-178         [-1, 1024, 38, 38]           2,048\n",
            "            ReLU-179         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-180         [-1, 1024, 38, 38]       9,437,184\n",
            "          Conv2d-181         [-1, 1024, 38, 38]       1,048,576\n",
            "   SeparableConv-182         [-1, 1024, 38, 38]               0\n",
            "     BatchNorm2d-183         [-1, 1024, 38, 38]           2,048\n",
            "       MaxPool2d-184         [-1, 1024, 19, 19]               0\n",
            "          Conv2d-185         [-1, 1024, 19, 19]         746,496\n",
            "     BatchNorm2d-186         [-1, 1024, 19, 19]           2,048\n",
            "          Conv2d-187         [-1, 1024, 19, 19]       9,437,184\n",
            "          Conv2d-188         [-1, 1536, 19, 19]       1,572,864\n",
            "   SeparableConv-189         [-1, 1536, 19, 19]               0\n",
            "     BatchNorm2d-190         [-1, 1536, 19, 19]           3,072\n",
            "            ReLU-191         [-1, 1536, 19, 19]               0\n",
            "          Conv2d-192         [-1, 1536, 19, 19]      21,233,664\n",
            "          Conv2d-193         [-1, 2048, 19, 19]       3,145,728\n",
            "   SeparableConv-194         [-1, 2048, 19, 19]               0\n",
            "     BatchNorm2d-195         [-1, 2048, 19, 19]           4,096\n",
            "            ReLU-196         [-1, 2048, 19, 19]               0\n",
            "AdaptiveAvgPool2d-197           [-1, 2048, 1, 1]               0\n",
            "        ExitFlow-198           [-1, 2048, 1, 1]               0\n",
            "          Linear-199                   [-1, 10]          20,490\n",
            "================================================================\n",
            "Total params: 186,777,042\n",
            "Trainable params: 186,777,042\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.02\n",
            "Forward/backward pass size (MB): 2907.05\n",
            "Params size (MB): 712.50\n",
            "Estimated Total Size (MB): 3620.57\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HSAtgJPxeV1l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 본격적으로 학습을 위한 함수를 제작하자\n",
        "# 하나의 batch_set의 데이터들의 손실함수가 모두 합산되어 반환되도록 정의\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# 30회마다 Learning rate를 10분의 1로 줄여주는 Scheduler 제작\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=8)\n",
        "\n",
        "# optimizer의 현재 Learning rate를 반환하는 함수 제작\n",
        "def get_lr(opt):\n",
        "  return opt.param_groups[0]['lr']\n",
        "\n",
        "# model의 예측과 정답 label을 비교하여 맞춘 개수를 반환한다\n",
        "def metric_batch(output, target):\n",
        "  pred = output.argmax(dim=1, keepdim=True)\n",
        "  corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "  return corrects\n",
        "\n",
        "# batct학습 시 손실함수 이용하여 backpropagation을 하고 나서\n",
        "# 해당 batch의 총 loss값과 맞은 정답의 개수를 반환하는 함수\n",
        "\n",
        "def loss_batch(loss_func, outputs, target, opt=None):\n",
        "  # 만약 Auxiliary Classifier가 적용된 모델이 반환한 값이라면\n",
        "  # Main Classifier의 반환값, Aux. classifier 1,2의 반환값이 return된다\n",
        "  if len(outputs) == 3:\n",
        "    output, aux1, aux2 = outputs\n",
        "  \n",
        "    output_loss = loss_func(output, target)\n",
        "    aux1_loss = loss_func(aux1, target)\n",
        "    aux2_loss = loss_func(aux2, target)\n",
        "\n",
        "    # Aux. Classifier의 loss는 0.3을 곱하여 전체 loss에 더한다\n",
        "    loss = output_loss + 0.3*(aux1_loss + aux2_loss)\n",
        "\n",
        "    # 해당 batch_dataset에서 model이 맞춘 정답의 개수\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "  else:\n",
        "    loss = loss_func(outputs, target)\n",
        "    metric_b = metric_batch(outputs, target)\n",
        "\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "  return loss.item(), metric_b\n",
        "\n",
        "# 해당 dataloader를 이용해 model을 1 epoch 훈련시키고\n",
        "# 1epoch동안의 평균 손실함수값과 정확도를 반환하는 함수\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "  # epoch 동안의 평균 손실함수값\n",
        "  # epoch 동안의 평균 Precision 저장을 위한 변수 생성\n",
        "  running_loss = 0.0\n",
        "  running_metric = 0.0\n",
        "  len_data = len(dataset_dl.dataset)\n",
        "\n",
        "  for xb, yb in dataset_dl:\n",
        "    xb, yb = xb.to(device), yb.to(device)\n",
        "    output = model(xb)\n",
        "\n",
        "    loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "    running_loss += loss_b\n",
        "\n",
        "    if metric_b is not None:\n",
        "      running_metric += metric_b\n",
        "\n",
        "    if sanity_check is True:\n",
        "      break\n",
        "\n",
        "  loss = running_loss  / len_data\n",
        "  metric = running_metric / len_data\n",
        "\n",
        "  return loss, metric\n",
        "\n",
        "# configuration parameter를 params라는 인자로 전달하면\n",
        "# 해당 config에 맞게 Train을 해주는 함수를 정의하였다\n",
        "def train_val(model, params):\n",
        "  num_epochs=params[\"num_epochs\"]\n",
        "  loss_func=params[\"loss_func\"]\n",
        "  opt=params[\"optimizer\"]\n",
        "  train_dl=params[\"train_dl\"]\n",
        "  val_dl=params[\"val_dl\"]\n",
        "  sanity_check=params[\"sanity_check\"]\n",
        "  lr_scheduler=params[\"lr_scheduler\"]\n",
        "  path2weights=params[\"path2weights\"]\n",
        "\n",
        "  # epoch별 평균 loss와 정확도를 저장\n",
        "  loss_history = {'train':[], 'val':[]}\n",
        "  metric_history = {'train':[], 'val':[]}\n",
        "\n",
        "  # 가장 작은 손실함수값을 반환하는 모델의 가중치를 저장한다\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = float('inf')\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr)) \n",
        "\n",
        "    # 학습 모드\n",
        "    model.train()\n",
        "    # train_dataset 1 Epoch 훈련\n",
        "    train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "    \n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # 모델의 성능 평가모드\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      torch.save(model.state_dict(), path2weights)\n",
        "      print(\"Copied best model weights!\")\n",
        "\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "    lr_scheduler.step(val_loss)\n",
        "    if current_lr != get_lr(opt):\n",
        "      print('Loading best model weights!')\n",
        "      model.load_state_dict(best_model_wts)\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)\n",
        "\n",
        "  # 학습을 모두 마치기 전 가장 손실함수가 적게 반환된 가중치로 모델을 초기화한다\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "oMJVYm_QybU-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델에 삽입할 config parameter를 정의한다\n",
        "params_train = {\n",
        "    'num_epochs':10,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# check the directory to save weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ],
      "metadata": {
        "id": "MiaH-nWAesje"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 epoch 학습 시작\n",
        "# Colab Out of Memory Error인하여 실험 진행 불가능\n",
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "1Zl3jzJce0o-",
        "outputId": "008af1f9-a4f8-47bf-83af-c6dab13bdb4a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9, current lr=0.01\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d4ae47d42c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 10 epoch 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-8f15550e7e10>\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# train_dataset 1 Epoch 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanity_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8f15550e7e10>\u001b[0m in \u001b[0;36mloss_epoch\u001b[0;34m(model, loss_func, dataset_dl, sanity_check, opt)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mloss_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-d6d4b364f1ff>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7477fc695061>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_residual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_shortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3_residual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3_shortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 350.00 MiB (GPU 0; 14.76 GiB total capacity; 13.09 GiB already allocated; 219.75 MiB free; 13.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}