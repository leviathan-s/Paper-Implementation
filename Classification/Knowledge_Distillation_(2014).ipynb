{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knowledge Distillation (2014).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "eY2A8ZUTo8uO"
      },
      "outputs": [],
      "source": [
        "# 필요한 module import하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "# 시각화할 때 Jupitor Notebook내장 그래픽카드를 사용\n",
        "\n",
        "## device 정의\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset을 이용하여 학습 및 평가를 진행할 예정이다\n",
        "# 먼저 Data를 저장할 Directory를 생성한다\n",
        "def createDir(directory):\n",
        "  if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "  return\n",
        "\n",
        "# MNIST Dataset을 저장할 ./data 디렉토리를 만든다\n",
        "createDir(\"./data\")"
      ],
      "metadata": {
        "id": "AvdUBgNmpYw9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset을 로드할 때 사용할 Pre-processor를 정의한다\n",
        "ds_transform = transforms.Compose([\n",
        "                    transforms.ToTensor(), # 0-1사이 값으로 정규화하고 텐서 type으로 반환\n",
        "                    transforms.Normalize(0.1307,0.3081) # mnist dataset의 pixel mean,std값으로 표준화한다\n",
        "])\n",
        "\n",
        "# Dataset 생성하기\n",
        "train_ds = datasets.MNIST(\"./data\", train=True, download=True, transform=ds_transform)\n",
        "val_ds = datasets.MNIST(\"./data\", train=False, download=True, transform=ds_transform)"
      ],
      "metadata": {
        "id": "0zAMY5Hxpk_1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset을 batch_size만큼 불러오는 DataLoader를 생성한다\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=128, shuffle=True)\n"
      ],
      "metadata": {
        "id": "jomZzYedquSO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 이미지를 출력해보자\n",
        "import numpy as np\n",
        "for x,y in train_dl:\n",
        "  print(x.shape, y.shape)\n",
        "  break\n",
        "\n",
        "num=4\n",
        "img = x[:num]\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range(num):\n",
        "  plt.subplot(1,num+1,i+1) # nrows, ncols, index\n",
        "  # Dataloader를 거치며 normalized되었으므로 다시 denormalize하여 출력해야 한다\n",
        "  # to_pil_image는 tensor Data를 pil image로 변형해주는 함수이다\n",
        "  plt.imshow(to_pil_image(0.1307*img[i] + 0.3081), cmap=\"gray\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "l70bPBoWrQa1",
        "outputId": "541336be-6585-45cc-f970-baacf67f4d3d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Knowledge distillation을 하기 위해 soft label을 얻기 위한 teacher model을 먼저 학습하자\n",
        "# teacher model을 다음과 같이 정의한다\n",
        "class Teacher(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(28*28,1200)\n",
        "    self.bn1 = nn.BatchNorm1d(1200)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.drop1 = nn.Dropout(p=0.8)\n",
        "    self.fc2 = nn.Linear(1200,1200)\n",
        "    self.bn2 = nn.BatchNorm1d(1200)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.drop2 = nn.Dropout(p=0.8)\n",
        "    self.fc3 = nn.Linear(1200,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1,28*28)\n",
        "    x = self.fc1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.drop1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.drop2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "IQJ7tNxuu0X0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teacher model에 입력값을 넣고 테스트를 해보자\n",
        "x = torch.randn(16,1,28,28).to(device)\n",
        "teacher = Teacher().to(device)\n",
        "output = teacher(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtcEXxDMwpwV",
        "outputId": "7ca6b009-23e9-4162-8c21-96c9851b9501"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3389, -1.6431,  0.7968,  0.5736,  0.7454,  0.6468,  1.8093, -1.7720,\n",
            "          0.3671, -1.7207],\n",
            "        [-1.2962, -0.4796,  0.6589, -0.7647, -2.3654, -0.2270, -0.0310,  0.6763,\n",
            "          2.5012,  0.8461],\n",
            "        [ 0.2039, -0.5975,  0.3290,  0.7841,  1.2047, -1.0596,  0.8631,  1.4324,\n",
            "          0.4886, -1.4230],\n",
            "        [-0.0157, -0.2025,  0.9359, -0.7085, -0.7282, -0.6089,  1.3473,  2.4791,\n",
            "         -1.3084, -1.2400],\n",
            "        [ 0.4646,  0.2422, -0.2455, -0.6578, -1.0673,  0.7564,  0.3990,  0.0502,\n",
            "          1.0603,  0.9334],\n",
            "        [-0.9606, -0.2603, -0.7226, -1.0616,  0.2517,  1.0162, -2.2670,  0.9036,\n",
            "          1.6993,  2.0685],\n",
            "        [ 0.6198,  0.1433, -0.4563, -0.0371,  0.4415, -0.2286, -1.4673,  0.3396,\n",
            "          0.5090,  1.0395],\n",
            "        [ 0.8614, -0.1932,  0.8354, -0.7852,  1.0638,  0.8401,  0.6140, -0.2054,\n",
            "         -0.7531,  0.9859],\n",
            "        [-0.6253, -1.6830,  0.7975,  0.4966,  1.2659, -1.0490,  2.3072,  1.3830,\n",
            "          0.7982, -1.2676],\n",
            "        [ 0.6945, -0.5226,  0.2939, -0.0700,  0.3620, -0.2231,  1.2472,  1.1882,\n",
            "          0.6352, -0.7709],\n",
            "        [-0.4082,  0.7696, -0.6230,  1.0899, -0.8607,  0.3985,  0.9824,  0.1872,\n",
            "          1.0968,  0.1134],\n",
            "        [-1.0791, -2.3069,  0.4295, -0.4167, -0.9089,  0.1426, -0.4742,  0.2474,\n",
            "          0.9403, -1.4825],\n",
            "        [-0.5082,  0.9177,  0.3583, -0.9921,  0.6794, -0.8437,  0.8417,  0.9026,\n",
            "          1.9817,  0.2916],\n",
            "        [ 1.0712,  0.0156,  0.0178,  0.0563, -0.0581,  0.6026,  0.2110,  0.9003,\n",
            "         -0.7631,  1.5262],\n",
            "        [ 0.4213,  1.7166, -0.5995,  1.5517,  0.4918,  0.4843,  0.1472, -1.2580,\n",
            "          0.3898, -1.2250],\n",
            "        [ 1.3411, -1.3461,  2.1704, -0.2933, -0.4702, -0.8813, -0.5243,  1.4682,\n",
            "          0.0166, -1.1353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 가중치를 초기화하는 함수를 정의하고\n",
        "# 해당 모델에 적용한다\n",
        "\n",
        "def initialize_weights(model):\n",
        "  classname = model.__class__.__name__\n",
        "\n",
        "  # 만약 FC Layer라면 다음과 같이 가중치를 초기화한다\n",
        "  if classname.find(\"Linear\") != -1:\n",
        "    nn.init.normal_(model.weight.data, 0.0, 0.02) # 평균이 0이고 표준편차0.02인 가우시안 정규분포로 초기화\n",
        "    nn.init.constant_(model.bias.data,0) # Bias는 0으로 초기화\n",
        "\n",
        "  # batch normalization 게층은 다음과 같이 초기화\n",
        "  elif classname.find(\"BatchNorm\") != -1:\n",
        "    nn.init.normal_(model.weight.data, 1.0, 0.02) # 평균이 1이고 표준편차 0.02인 가우시안 정규분포 난수\n",
        "    nn.init.constant_(model.bias.data, 0)\n",
        "\n",
        "teacher.apply(initialize_weights) # teacher모델에 해당 가중치 초기화 함수를 적용한다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiFdzfl_xjMm",
        "outputId": "319ecc53-32c8-47c0-dbf4-2786258868ec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Teacher(\n",
              "  (fc1): Linear(in_features=784, out_features=1200, bias=True)\n",
              "  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (drop1): Dropout(p=0.8, inplace=False)\n",
              "  (fc2): Linear(in_features=1200, out_features=1200, bias=True)\n",
              "  (bn2): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu2): ReLU()\n",
              "  (drop2): Dropout(p=0.8, inplace=False)\n",
              "  (fc3): Linear(in_features=1200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teacher model을 학습하기 위한 여러 함수를 정의한다\n",
        "\n",
        "# 본격적으로 학습을 위한 함수를 제작하자\n",
        "# 하나의 batch_set의 데이터들의 손실함수가 모두 합산되어 반환되도록 정의\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(teacher.parameters())\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# 30회마다 Learning rate를 10분의 1로 줄여주는 Scheduler 제작\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode=\"min\", factor=0.1, patience=10)\n",
        "\n",
        "# optimizer의 현재 Learning rate를 반환하는 함수 제작\n",
        "def get_lr(opt):\n",
        "  return opt.param_groups[0]['lr']\n",
        "\n",
        "# model의 예측과 정답 label을 비교하여 맞춘 개수를 반환한다\n",
        "def metric_batch(output, target):\n",
        "  pred = output.argmax(dim=1, keepdim=True)\n",
        "  corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "  return corrects\n",
        "\n",
        "# batct학습 시 손실함수 이용하여 backpropagation을 하고 나서\n",
        "# 해당 batch의 총 loss값과 맞은 정답의 개수를 반환하는 함수\n",
        "\n",
        "def loss_batch(loss_func, outputs, target, opt=None):\n",
        "  # 만약 Auxiliary Classifier가 적용된 모델이 반환한 값이라면\n",
        "  # Main Classifier의 반환값, Aux. classifier 1,2의 반환값이 return된다\n",
        "  if len(outputs) == 3:\n",
        "    output, aux1, aux2 = outputs\n",
        "  \n",
        "    output_loss = loss_func(output, target)\n",
        "    aux1_loss = loss_func(aux1, target)\n",
        "    aux2_loss = loss_func(aux2, target)\n",
        "\n",
        "    # Aux. Classifier의 loss는 0.3을 곱하여 전체 loss에 더한다\n",
        "    loss = output_loss + 0.3*(aux1_loss + aux2_loss)\n",
        "\n",
        "    # 해당 batch_dataset에서 model이 맞춘 정답의 개수\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "  else:\n",
        "    loss = loss_func(outputs, target)\n",
        "    metric_b = metric_batch(outputs, target)\n",
        "\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "  return loss.item(), metric_b\n",
        "\n",
        "# 해당 dataloader를 이용해 model을 1 epoch 훈련시키고\n",
        "# 1epoch동안의 평균 손실함수값과 정확도를 반환하는 함수\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "  # epoch 동안의 평균 손실함수값\n",
        "  # epoch 동안의 평균 Precision 저장을 위한 변수 생성\n",
        "  running_loss = 0.0\n",
        "  running_metric = 0.0\n",
        "  len_data = len(dataset_dl.dataset)\n",
        "\n",
        "  for xb, yb in dataset_dl:\n",
        "    xb, yb = xb.to(device), yb.to(device)\n",
        "    output = model(xb)\n",
        "\n",
        "    loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "    running_loss += loss_b\n",
        "\n",
        "    if metric_b is not None:\n",
        "      running_metric += metric_b\n",
        "\n",
        "    if sanity_check is True:\n",
        "      break\n",
        "\n",
        "  loss = running_loss  / len_data\n",
        "  metric = running_metric / len_data\n",
        "\n",
        "  return loss, metric\n",
        "\n",
        "# configuration parameter를 params라는 인자로 전달하면\n",
        "# 해당 config에 맞게 Train을 해주는 함수를 정의하였다\n",
        "def train_val(model, params):\n",
        "  num_epochs=params[\"num_epochs\"]\n",
        "  loss_func=params[\"loss_func\"]\n",
        "  opt=params[\"optimizer\"]\n",
        "  train_dl=params[\"train_dl\"]\n",
        "  val_dl=params[\"val_dl\"]\n",
        "  sanity_check=params[\"sanity_check\"]\n",
        "  lr_scheduler=params[\"lr_scheduler\"]\n",
        "  path2weights=params[\"path2weights\"]\n",
        "\n",
        "  # epoch별 평균 loss와 정확도를 저장\n",
        "  loss_history = {'train':[], 'val':[]}\n",
        "  metric_history = {'train':[], 'val':[]}\n",
        "\n",
        "  # 가장 작은 손실함수값을 반환하는 모델의 가중치를 저장한다\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = float('inf')\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs - 1, current_lr)) \n",
        "\n",
        "    # 학습 모드\n",
        "    model.train()\n",
        "    # train_dataset 1 Epoch 훈련\n",
        "    train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "    \n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # 모델의 성능 평가모드\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      torch.save(model.state_dict(), path2weights)\n",
        "      print(\"Copied best model weights!\")\n",
        "\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "    lr_scheduler.step(val_loss)\n",
        "    if current_lr != get_lr(opt):\n",
        "      print('Loading best model weights!')\n",
        "      model.load_state_dict(best_model_wts)\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)\n",
        "\n",
        "  # 학습을 모두 마치기 전 가장 손실함수가 적게 반환된 가중치로 모델을 초기화한다\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "oMJVYm_QybU-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter config를 정의하고 학습할 준비를 완료하였다.\n",
        "params_train = {\n",
        "    'num_epochs':30,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/teacher_weights.pt',\n",
        "}\n",
        "\n",
        "createDir('./models')"
      ],
      "metadata": {
        "id": "FiZhzvSTy8WV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher, loss_hist, metric_hist = train_val(teacher, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoBJEgyBzl0m",
        "outputId": "2496e2d2-07ea-49c2-8f62-43dd4e153be9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.466418, val loss: 0.161639, accuracy: 94.94, time: 0.2069 min\n",
            "----------\n",
            "Epoch 1/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.311681, val loss: 0.128619, accuracy: 95.96, time: 0.4131 min\n",
            "----------\n",
            "Epoch 2/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.267931, val loss: 0.111358, accuracy: 96.57, time: 0.6193 min\n",
            "----------\n",
            "Epoch 3/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.243413, val loss: 0.106090, accuracy: 96.68, time: 0.8264 min\n",
            "----------\n",
            "Epoch 4/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.228286, val loss: 0.096674, accuracy: 97.01, time: 1.0340 min\n",
            "----------\n",
            "Epoch 5/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.210308, val loss: 0.091029, accuracy: 97.08, time: 1.2407 min\n",
            "----------\n",
            "Epoch 6/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.200573, val loss: 0.086191, accuracy: 97.24, time: 1.4545 min\n",
            "----------\n",
            "Epoch 7/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.188797, val loss: 0.081980, accuracy: 97.48, time: 1.6610 min\n",
            "----------\n",
            "Epoch 8/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.178885, val loss: 0.079074, accuracy: 97.59, time: 1.8668 min\n",
            "----------\n",
            "Epoch 9/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.176989, val loss: 0.076390, accuracy: 97.60, time: 2.0750 min\n",
            "----------\n",
            "Epoch 10/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.167510, val loss: 0.076247, accuracy: 97.62, time: 2.2827 min\n",
            "----------\n",
            "Epoch 11/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.158559, val loss: 0.072399, accuracy: 97.77, time: 2.4884 min\n",
            "----------\n",
            "Epoch 12/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.153365, val loss: 0.068747, accuracy: 97.79, time: 2.6936 min\n",
            "----------\n",
            "Epoch 13/29, current lr=0.001\n",
            "train loss: 0.152782, val loss: 0.070340, accuracy: 97.80, time: 2.8997 min\n",
            "----------\n",
            "Epoch 14/29, current lr=0.001\n",
            "train loss: 0.147280, val loss: 0.071093, accuracy: 97.82, time: 3.1062 min\n",
            "----------\n",
            "Epoch 15/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.137507, val loss: 0.066552, accuracy: 97.97, time: 3.3115 min\n",
            "----------\n",
            "Epoch 16/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.143170, val loss: 0.064462, accuracy: 98.03, time: 3.5209 min\n",
            "----------\n",
            "Epoch 17/29, current lr=0.001\n",
            "train loss: 0.135619, val loss: 0.068238, accuracy: 97.95, time: 3.7262 min\n",
            "----------\n",
            "Epoch 18/29, current lr=0.001\n",
            "train loss: 0.135883, val loss: 0.065148, accuracy: 97.92, time: 3.9323 min\n",
            "----------\n",
            "Epoch 19/29, current lr=0.001\n",
            "train loss: 0.132627, val loss: 0.064917, accuracy: 98.08, time: 4.1379 min\n",
            "----------\n",
            "Epoch 20/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.127972, val loss: 0.062998, accuracy: 98.05, time: 4.3427 min\n",
            "----------\n",
            "Epoch 21/29, current lr=0.001\n",
            "train loss: 0.127140, val loss: 0.064722, accuracy: 98.01, time: 4.5489 min\n",
            "----------\n",
            "Epoch 22/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.121175, val loss: 0.061606, accuracy: 98.15, time: 4.7536 min\n",
            "----------\n",
            "Epoch 23/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.122544, val loss: 0.058823, accuracy: 98.20, time: 4.9600 min\n",
            "----------\n",
            "Epoch 24/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.116652, val loss: 0.058210, accuracy: 98.22, time: 5.1648 min\n",
            "----------\n",
            "Epoch 25/29, current lr=0.001\n",
            "train loss: 0.116539, val loss: 0.059720, accuracy: 98.17, time: 5.3693 min\n",
            "----------\n",
            "Epoch 26/29, current lr=0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.116543, val loss: 0.056893, accuracy: 98.16, time: 5.5743 min\n",
            "----------\n",
            "Epoch 27/29, current lr=0.001\n",
            "train loss: 0.114157, val loss: 0.057747, accuracy: 98.15, time: 5.7794 min\n",
            "----------\n",
            "Epoch 28/29, current lr=0.001\n",
            "train loss: 0.110064, val loss: 0.057068, accuracy: 98.26, time: 5.9846 min\n",
            "----------\n",
            "Epoch 29/29, current lr=0.001\n",
            "train loss: 0.112232, val loss: 0.057467, accuracy: 98.21, time: 6.1922 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher model이 학습하면서 기록된 loss와 accuracy를 시각화한다\n",
        "num_epochs = params_train['num_epochs']\n",
        "\n",
        "# Plot train-val loss\n",
        "plt.title('Train-Val Loss')\n",
        "plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot train-val accuracy\n",
        "plt.title('Train-Val Accuracy')\n",
        "plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "TZeVDr9u10wh",
        "outputId": "3036568e-6fc8-4530-d036-ef982aee5664"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wc9Z3/8ddnV713d1tyxTYEA7ZpNi0JECAmF46SAEm4UHIHCam/I/nd/cLlkku9FEInECAJnRQuCZBLgrEpBstgim3AtixjuUqyitXb9/fHjOy1kIwka7XanffzkXnM7OzszGeyeD/61jHnHCIiElyhWAcgIiKxpUQgIhJwSgQiIgGnRCAiEnBKBCIiAadEICIScEoEEkhm9qSZfXqUr3mamVWN5jVFBkOJQOKGmTVFLD1m1hrx+tKhnMs59xHn3H1DvH6amdWb2Rn9vPcTM3tsKOfr5xzOzGYezjlEhkOJQOKGcy6rdwHeBT4ase83vceZWVKUrt8GPAx8KnK/mYWBTwBDSiwiY4USgcS93ioXM/tXM9sF/NLM8s3sj2ZWbWZ1/vbkiM8sN7Mr/e3PmNlzZvYj/9gtZvaRAS53H3CBmWVE7DsL79/Sk2Z2hZltMLN9ZlZhZteMwP3lmtn9/r1sNbN/M7OQ/95MM3vWzBrMrMbMHvb3m19K2WNmjWb2hpkdebixSGJSIpBEMR4oAKYBV+P9t/1L//VUoBW4+RCfPx54GygCfgDcbWbW9yDn3AvATuDjEbsvBx5wznUBe4DzgBzgCuAnZnbsYd0Z/BzIBaYDp+KVSK7w3/tP4C9APjDZPxbgTOAUYLb/2YuA2sOMQxKUEoEkih7gm865dudcq3Ou1jn3uHOuxTm3D/gO3o/oQLY65+5yznXj/dU/ARg3wLH341cPmVkOcL7/GZxzf3LObXaeZ/F+pJcO96b8aqdLgK875/Y55yqB/8ZLPgCdeMluonOuzTn3XMT+bOAIwJxzG5xzO4cbhyQ2JQJJFNV+HT4AZpZhZnf4VSmNwAogz/9h7c+u3g3nXIu/mWVmSyMapNf5+38FnG5mE4F/BDY75171r/sRM1tlZnvNrB44B6+UMVxFQDKwNWLfVmCSv/1/AANeNrN1ZvZP/j38Ha8EdAuwx8zu9JOWyHsoEUii6DuN7leAOcDxzrkcvGoS8H40B39S51ZGNEjP9/dtBVYCl+H9ZX4fgJmlAo8DPwLGOefygD8P9Zp91HDgr/5eU4Htfiy7nHNXOecmAtcAt/b2PHLO3eScOw6Yh1dF9LXDiEMSmBKBJKpsvHaBejMrAL45wue/D7gOOBno7bGUAqQC1UCX3+B85hDPm+J3U00zszR/3yPAd8ws28ymAV8Gfg1gZhdGNILX4SXEHjNbZGbHm1ky0Ay04VWfibyHEoEkqp8C6Xh/Ua8Cnhrh8z+O1zj9t966d78t4gt4P9x1wCeBJ4Z43nV4Cax3uQL4PN6PeQXwHPAAcI9//CLgJTNr8q91vXOuAq+x+i4/jq14DcU/HM6NSuIzPZhGRCTYVCIQEQk4JQIRkYBTIhARCTglAhGRgIvK5FzRVFRU5EpLS2MdhohIXFmzZk2Nc664v/fiLhGUlpZSXl4e6zBEROKKmW0d6D1VDYmIBJwSgYhIwCkRiIgEXNy1EYiIDEdnZydVVVW0tbW9/8FxLC0tjcmTJ5OcnDzozygRiEggVFVVkZ2dTWlpKf08cyghOOeora2lqqqKsrKyQX9OVUMiEghtbW0UFhYmbBIAMDMKCwuHXOpRIhCRwEjkJNBrOPcYmERQXrmX7z/1FpptVUTkYIFJBG9sb+C25ZvZ29wR61BEJIDq6+u59dZbh/y5c845h/r6+ihEdEBgEkFpYSYAlbUt73OkiMjIGygRdHV1HfJzf/7zn8nLy4tWWECAEsG0wgwAttY2xzgSEQmiG264gc2bN7NgwQIWLVrE0qVLWbZsGfPmzQPgYx/7GMcddxzz58/nzjvv3P+50tJSampqqKysZO7cuVx11VXMnz+fM888k9bW1hGJLTDdRyfnZxAylQhEBP7jf9axfkfjiJ5z3sQcvvnR+QO+/73vfY8333yTtWvXsnz5cs4991zefPPN/d0877nnHgoKCmhtbWXRokVccMEFFBYWHnSOjRs38uCDD3LXXXdx0UUX8fjjj3PZZZcdduyBSQQpSSEm5aerRCAiY8LixYsP6ut/00038bvf/Q6Abdu2sXHjxvckgrKyMhYsWADAcccdR2Vl5YjEEphEAF47gUoEInKov9xHS2Zm5v7t5cuX89e//pUXX3yRjIwMTjvttH7HAqSmpu7fDofDI1Y1FJg2AvDaCVQiEJFYyM7OZt++ff2+19DQQH5+PhkZGbz11lusWrVqVGMLXImgvqWT+pYO8jJSYh2OiARIYWEhJ598MkceeSTp6emMGzdu/3tnn302t99+O3PnzmXOnDmccMIJoxpboBLBNL8L6dbaFiUCERl1DzzwQL/7U1NTefLJJ/t9r7cdoKioiDfffHP//q9+9asjFlfgqoYAKlU9JCKyX6ASwdSC3rEEajAWEekVqESQlhxmQm6aSgQiIhEClQigt+eQSgQiIr0ClwhKCzPVhVREJELgEsG0wkxqmjrY19YZ61BERMaEwCWC0kI1GIvI2JeVlTVq1wpcIogcSyAiIgEbUAYaSyAisXHDDTcwZcoUrr32WgBuvPFGkpKSeOaZZ6irq6Ozs5Nvf/vbnH/++aMeW+ASQWZqEsXZqWowFgmyJ2+AXW+M7DnHHwUf+d6Ab1988cV88Ytf3J8IHnnkEZ5++mm+8IUvkJOTQ01NDSeccALLli0b9WcrBy4RgNdOoFlIRWQ0HXPMMezZs4cdO3ZQXV1Nfn4+48eP50tf+hIrVqwgFAqxfft2du/ezfjx40c1tkAmgmmFmazcWB3rMEQkVg7xl3s0XXjhhTz22GPs2rWLiy++mN/85jdUV1ezZs0akpOTKS0t7Xf66WgLXGMxeCWC3Y3ttHQc+lmhIiIj6eKLL+ahhx7iscce48ILL6ShoYGSkhKSk5N55pln2Lp1a0ziCmQi6O059O5eVQ+JyOiZP38++/btY9KkSUyYMIFLL72U8vJyjjrqKO6//36OOOKImMQVyKqhUj8RVNa0cMT4nBhHIyJB8sYbBxqpi4qKePHFF/s9rqmpabRCCmaJYOr+QWXqOSQiEshEkJueTEFminoOiYgQ0EQAen6xSBA552IdQtQN5x4Dmwi8WUhVIhAJirS0NGpraxM6GTjnqK2tJS0tbUifC2RjMXglgt+v3U5bZzdpyeFYhyMiUTZ58mSqqqqork7sMURpaWlMnjx5SJ+JaiIws7OBnwFh4BfOuX5HcZjZBcBjwCLnXHk0Y+pVWpiJc1BV18LMkuzRuKSIxFBycjJlZWWxDmNMilrVkJmFgVuAjwDzgE+Y2bx+jssGrgdeilYs/dk/+VyNqodEJNii2UawGNjknKtwznUADwH9Tav3n8D3gVEdV71/LIEajEUk4KKZCCYB2yJeV/n79jOzY4Epzrk/HepEZna1mZWbWflI1e/lZSSTk5akBmMRCbyY9RoysxDwY+Ar73esc+5O59xC59zC4uLikbo+pUWZKhGISOBFMxFsB6ZEvJ7s7+uVDRwJLDezSuAE4AkzWxjFmA4yTV1IRUSimghWA7PMrMzMUoBLgCd633TONTjnipxzpc65UmAVsGy0eg2BNwtpVV0LHV09o3VJEZExJ2qJwDnXBVwHPA1sAB5xzq0zs2+Z2bJoXXcophVm0uNge31rrEMREYmZqI4jcM79Gfhzn33/b4BjT4tmLP0pjXh+cVlR5mhfXkRkTAjsFBNw4LkEW2vUYCwiwRXoRFCUlUJmSlizkIpIoAU6EZiZ33NIJQIRCa5AJwKA0qIMdSEVkUALfCKYVpjJtroWurrVhVREginwiaC0MIPObsfOhlGd6khEZMwIfCLY33NI1UMiElCBTwSahVREgi7wiaAkO5W05JB6DolIYAU+EYRCxrSCTI0lEJHACnwiAO9pZSoRiEhQKREApUXedNQ9PS7WoYiIjDolArwSQXtXD7v3qQupiASPEgERPYf0IHsRCSAlArwSAaB2AhEJJCUCYEJuOinhkHoOiUggKREA4ZAxpSBdJQIRCSQlAt+0Qo0lEJFgUiLw9Y4lcE5dSEUkWJQIfKWFmbR0dFPd1B7rUERERpUSge9AzyFVD4lIsCgR+A6MJVCDsYgEixKBb1J+OuGQqUQgIoGjROBLDoeYnJ+u5xKISOAoEUSYVpipEoGIBI4SQYTSwgwq1YVURAJGiSDCtMJM9rV1UdfSGetQRERGjRJBhFK/C6naCUQkSJQIIkzzu5BqziERCRIlgghTCtIx03MJRCRYlAgipCaFmZirWUhFJFiUCPooLcrQLKQiEihKBH14YwlUIhCR4FAi6KO0MIO6lk4a1IVURAJCiaCP/T2H9qpUICLBoETQx/5ZSNVOICIBoUTQx9QCb1DZpj1NMY5ERGR0KBH0kZ4SZlFpPo+Wb6O9qzvW4YiIRJ0SQT8+f8Ysdja08Wh5VaxDERGJuqgmAjM728zeNrNNZnZDP+9/zszeMLO1Zvacmc2LZjyDtXRWEcdMzeO25Zvp6OqJdTgiIlEVtURgZmHgFuAjwDzgE/380D/gnDvKObcA+AHw42jFMxRmxhc/NJvt9a08tkalAhFJbNEsESwGNjnnKpxzHcBDwPmRBzjnGiNeZgJj5kEAp8wqYsGUPG55ZpNKBSKS0KKZCCYB2yJeV/n7DmJm15rZZrwSwReiGM+QmBnXf2gW2+tbefwVlQpEJHHFvLHYOXeLc24G8K/Av/V3jJldbWblZlZeXV09arGdNruYoyfncsszm+jsVqlARBJTNBPBdmBKxOvJ/r6BPAR8rL83nHN3OucWOucWFhcXj2CIh9bbVlBV18pvVSoQkQQVzUSwGphlZmVmlgJcAjwReYCZzYp4eS6wMYrxDMtpc4r5wORcblapQEQSVNQSgXOuC7gOeBrYADzinFtnZt8ys2X+YdeZ2TozWwt8Gfh0tOIZLjPj+g/OYtveVn736qEKNCIi8cmcGzMddQZl4cKFrry8fFSv6Zxj2c3P09Dayd++cirJ4Zg3rYiIDImZrXHOLezvPf2iDUJvqeDdvS38XqUCEUkwSgSD9MG5JRw5KYebn9lEl9oKRCSBKBEMkpnxhTNmsbW2hT+s3RHrcERERowSwRB8eN445k1QqUBEEosSwRD0jjbeUtPME6+pVCAiiWFQicDMMs0s5G/PNrNlZpYc3dDGpjPnjWPuhBxu/vsmunviq8eViEh/BlsiWAGkmdkk4C/A5cC90QpqLPN6EM2koqaZ/1GpQEQSwGATgTnnWoCPA7c65y4E5kcvrLHtzHnjOWJ8Njf9faNKBSIS9wadCMzsROBS4E/+vnB0Qhr7QiFvXEFFdTN/fF2lAhGJb4NNBF8Evg78zp8mYjrwTPTCGvvOmj+eOeOy+dnfNtLWqWcbi0j8GlQicM4965xb5pz7vt9oXOOcGzPPDoiFUMi44Zwj2FLTzBcfWqsqIhGJW4PtNfSAmeWYWSbwJrDezL4W3dDGvtPnlPBv587jqXW7+M8/rife5m0SEYHBVw3N8x8r+THgSaAMr+dQ4H12SRlXLinj3hcquXNFRazDEREZsqRBHpfsjxv4GHCzc67TzPTnr+8b58xlV2Mb333yLcbnpnH+gvc8kVNEZMwabIngDqAS7wHzK8xsGtB4yE8ESChk/PdFR3N8WQFfffQ1XthUE+uQREQGbbCNxTc55yY5585xnq3A6VGOLa6kJoW581MLKSvK5JpfrWHDTuVJEYkPg20szjWzH/c+QN7M/huvdCARctOTufeKxWSmJnHFL1ezo7411iGJiLyvwVYN3QPsAy7yl0bgl9EKKp5NzEvn3n9aRHN7F5/55cs0tHbGOiQRkUMabCKY4Zz7pnOuwl/+A5gezcDi2RHjc7jjU8dRWdPC1feXa8CZiIxpg00ErWa2pPeFmZ0MqN7jEE6aUcSPLjqal7bs5SuPvkaPBpyJyBg12O6jnwPuN7Nc/3Ud8OnohJQ4lh09kV0NrfzXn99ifE4a/37evFiHJCLyHoNKBM6514CjzSzHf91oZl8EXo9mcIngqqXT2VHfxt3PbSFk8LWzjiAlSc8DEpGxY0i/SM65Rn+EMcCXoxBPwjEz/v28eVx6/FTuWrmF8295nnd274t1WCIi+x3On6Y2YlEkuHDI+M4/HMVdn1rInsY2zvv5c/xiZYXaDURkTDicRKBfsSH68LxxPP2lUzhlVjHf/tMGLrv7JY01EJGYO2QiMLN9ZtbYz7IPmDhKMSaUoqxU7vrUcXz/gqNYu62es366gj+s3a6ZS0UkZg6ZCJxz2c65nH6WbOfcYHscSR9mxsWLpvLk9UuZPS6b6x9ay+cffJX6lo5YhyYiAaTuKzE0rTCTR645ka+dNYen3tzFWT9dwcqN1bEOS0QCRokgxsIh49rTZ/L7a08mOy2Zy+9+mRufWEdHV0+sQxORgFAiGCOOnJTLHz+/hM+cVMq9L1Ry+d0vsbdZVUUiEn1KBGNIWnKYG5fN52eXLODVbfWcf8tzvL1LYw5EJLqUCMag8xdM4pFrTqS9s4eP3/o8f12/O9YhiUgCUyIYoxZMyeOJ65YwoySLq35Vzm3LN6uLqYhEhRLBGDY+N41HrjmR8z4wke8/9RZffuQ1TWktIiNOYwHGuLTkMDddsoA547L40V/eYUtNM3defhwlOWmxDk1EEoRKBHHAzLjujFncftlxvLN7H8tufp43qhpiHZaIJAglgjhy9pHjeexzJxEOGRfe8QJ/fH1HrEMSkQSgRBBn5k3M4Q/XncxRk3K57oFX+dLDa1m/o/H9PygiMgAlgjhUlJXKr688nmtOmc7T63Zxzk0rufQXq3jmrT2a2lpEhszirUviwoULXXl5eazDGDMaWjp5cPW73Pt8Jbsa25hZksVnl5TxD8dMIi05HOvwRGSMMLM1zrmF/b0X1RKBmZ1tZm+b2SYzu6Gf979sZuvN7HUz+5uZTYtmPIkoNyOZz506gxX/53R+cvHRpIRDfP23b3Dy9/7OT//6DjVN7bEOUUTGuKiVCMwsDLwDfBioAlYDn3DOrY845nTgJedci5n9M3Cac+7iQ51XJYJDc87xYkUtd6/cwt/e2kNKUogLjp3EZ5eUMbMkO9bhiUiMHKpEEM1xBIuBTc65Cj+Ih4Dzgf2JwDn3TMTxq4DLohhPIJgZJ80o4qQZRWza08Tdz23ht69U8dDqbVxw7GS+9OHZTMpLj3WYIjKGRLNqaBKwLeJ1lb9vIJ8FnuzvDTO72szKzay8ulrz9Q/WzJIsvvvxo3jhhjO4aul0nnhtB6f/aDnf/fMGGlo6Yx2eiIwRY6LXkJldBiwEftjf+865O51zC51zC4uLi0c3uARQmJXKN86Zy9+/cirnfWACd66sYOkP/s4dz27WlBUiEtVEsB2YEvF6sr/vIGb2IeD/Asucc2rZjKLJ+Rn8+KIF/PkLSzl2Wj7fffItzvjRch4t30a3up2KBFY0E8FqYJaZlZlZCnAJ8ETkAWZ2DHAHXhLYE8VYJMLcCTnce8ViHrjqeIqzU/naY69z7k0reeatPZrhVCSAopYInHNdwHXA08AG4BHn3Doz+5aZLfMP+yGQBTxqZmvN7IkBTidRcNKMIn5/7cnc/MljaO3s5op7V3PJnatYVVGrhCASIBpQJgB0dPXw0Op3uelvG6lp6uDoyblcfcoMzj5yPOGQxTo8ETlMh+o+qkQgB2nt6ObxV6r4xcoKKmtbmFqQwZVLy7jwuCmkp2ikski8UiKQIevucfzv+l3csaKCV9+tJz8jmctPmManTiqlKCs11uGJyBApEciwOedYs7WOO1ZU8NcNu0kJh7jguMlcuaSM6cVZsQ5PRAYpViOLJQGYGQtLC1hYWsDm6iZ+sbKCx9ZU8eDL73Li9EIm56dTmJVKYWYKxdmpFGamUpiVQmFWCgUZKSSFx8RQFRE5BJUIZMiq97Vz/4uV/P2tPdQ0tVPb1EFXP+MQzCA/I4WirBROm1PCp06cxuT8jNEPWERUNSTR5ZyjsbWL6qZ2apvaqW3uoLapneomb11V18pzm2pwznHW/PFccXIZi0rzMVNvJJHRoqohiSozIzcjmdyMZGaW9N9usKO+lV+t2soDL73Lk2/u4shJOVxxUhnnHT2B1CT1RhKJJZUIZFS1dnTz21er+OXzlWza00RRViqXnTCVS4+fRnG2eiOJRIuqhmTMcc6xcmMN9zy/heVvV5MSDvHRoydyxcmlHDkpN9bhiSQcVQ3JmGNmnDK7mFNmF7O5uol7n6/ksTVVPP5KFcdOzeOyE6ZxzlET9LhNkVGgEoGMGQ0tnTz2ShW/WbWVippm8jOSuWjhFD55/FSmFWbGOjyRuKaqIYB9u2HDE7D4qpEPSkaUc44XNtfy61Vb+cv63XT3OE6dXcxlJ0zjjCNKNPeRyDCoaghgzb2w/L8gbxrMPjPW0cghmBknzyzi5JlF7Gpo46HV7/Lgy+9y1f3lTMpL5xOLp3DxoqlqXBYZIcEpEXS1wx2nQFsjXLsK0tQgGU86u3v424bd/HrVuzy3qYbksHHs1HwWlxWwuKyAY6fmk5kanL9rRIZKVUO9qtbA3R+CYy6HZTeNbGAyaiqqm3i4fBsvbKpl3Y4GehyEQ8b8iTksKi3wl3wKNTmeyH5KBJH+8u/wwk1w+e9hxukjF5jERFN7F69srWN15V5e3rKXtdvqae/qAWBGcSaLywqYNzGX9OQwKUkhUsIhUpNC3rb/OjnsbacmhZiYl642CElISgSROlvh9iXQ1QH/8iKkagbNRNLe1c2b2xt4eUsdL2+ppXxrHfvaugb9+ey0JI4vK+CE6YWcML2QeRNyCCkxSAJQIujr3VVwz9mw6Eo490cjE5iMSd09jj372ujo6qGzu4f2rh46epfunoP2t3Z081pVPasq9rKlphmA3PTk/YnhxBmFzBmXrcQgcUm9hvqaegIc/zl46TaY/zEoXRLriCRKwiFjQm76oI+/ZPFUAHY2tLKqopYXN9fyYkUtf1m/G4D8jGSOLyvk1DnFnL9gIhkpwfwnJIklmCUCgI5muO0kwOCfX4AUTY8sA6uqa2FVxV5e3FzLqopatte3kpeRzKXHT+XTJ5ZSkpMW6xBFDklVQwPZsgLu+yiccC2c/V8jc05JeM45yrfWcdeKCv53w26SQyHOXzCRK5dOZ8747CGfr76lg1UVtdS1dPLBuSWUZCupyMhT1dBAyk6Bhf8Eq271qoimLI51RBIHzGx/N9UtNc3c89wWHl2zjUfXVHHK7GKuWlrGkplFAz5voaWji9WVdbywqYbnN9ewbkcjvX+PhQxOnFHIsqMncvb8CeRmJI/inUlQBbtEANC+D249EZLT4ZqVkKy/xmTo6po7+M1LW7n3ha3UNLVzxPhsrlw6nWVHTwRg7bZ6Xthcwwubanl1Wx2d3Y7ksHHM1HxOnlHESTMLyU5L4k+v7+SJ13awtbaF5LBx6uwSli2YyIfmlqg9Qg6Lqobez6a/wq8vgCVfgg/dOLLnlkBp7+rmD2t3cPfKLby9ex+FmSm0dHTT2tmNGRw1KZcTZxRy8owiFpUWkJ7y3tlVnXO8XtXA/7y2gz++vpNdjW2kJ4f58LxxfPToiZw6u5iUJD0LWoZGiWAw/nAtrH0QrvwrTDp25M8vgeKcY8XGGh5ZvY3CrBROmlHEidMLh1zV09PjeLlyL0+8toMn39hJXUsn2WlJFGel0u0c3T2Onh7nb0N3T4+3z3ldZ9OSQ5QWZVJWlMn0okymF2dRVpRJaWFmv0lIEpcSwWC01sOtJ0B6Plz9LCSljPw1RA5DZ3cPz22s4el1u2hq7yIcMsJmhCLWSSEjHDJCZoRD0NzRTWVNMxXVzexqbDvofBNz0/YnhrKiTOZPzOGoybmqgkpQSgSD9fZT8ODFcOq/wunfiM41RGKkub2LytpmtviJYUtNMxU1zVRUN+0ffR0OGbPHZbNgSh7HTMnj6Cl5zCzJ0rQbCUCJYCh+ezW8+bhXRTTxmOhdR2SMcM5R3dTOG1UNrN1Wv3/pTQ5ZqUkcNSmXBVPzWDAlj9njsslMCZOWEiY9OUxyWO0V8UCJYCha9noDzdqb4ON3wBHnRu9aImNUT49jS20za989kBg27Gykq+e9vxdJISMtOUxacpj0lBDpvdvJYY6alMvS2cUcX1agx47GmBLBUDVUwcOXwY5X4ZSvwWlfh5D+I5Zga+vsZt2ORiprmmnt7KbNX1o7u2nt6KG1s5v23ted3TS2dvLmjkY6unpISQpxfFkBS2cVccrsYuaMyx5wnIVEhxLBcHS2wZ++Amt/DTM/DBfc5TUki8igtXZ089KWWlZurGHlxmre2d0EQHF2qpcUZhWzZFYRRf6zI7q6e9jX1kVjWyeNrb3rzv2vm9q7mD0um5NnFpKXoQ4dQ6FEMFzOQfnd8OQNkDsZLvkNjJs/OtcWSUC7GtpYubGaFRtreG5jNXUtnQCMy0mlub2bpvbBTRluBh+YlMuSWUUsmVnMcdPyNbbifSgRHK53X4JHLvdGIZ9/Cxz58dG9vkgC6ulxrNvRyIqN1VTWNJOTnkxOWjI56Un+OpmctCRy0pPJTfdepyaFeL2qnpUba3huYw2vbqunu8eRkRLm+LIClswq5pRZRcwsyVLVUx9KBCNh3y545FOw7SU46fPwwRshrP7WIrHU2NbJqs1e1dNzm2r2P0diXE4qR03KIylkmEHIDLz/ETJvX++2t39wSSM1OcT4nDTG56YxITeNCbnpjM9NIysOnpetRDBSujrg6a/D6l9A2anwj7+EzMLYxCIi77FtbwvPbfLaIyqqm+lxDufAAT3+Ru+299LR0zP487d2drO3ueM9+7PTkpiQm8b43HQm+Ili1rgs5k/MZVpBxph4mJESwUh79dfwxy9D1ji46D5NSSESIG2d3expbGdnQyu7GtvYUd/GroZWdja0sauxjZ0NbdQ0te+fUTYjJRpCBogAAA/VSURBVMzcCTnMm5DD/Ik5zJuYw+xx2YfsTtva0c2efW3sbmw/aH3W/PEcO3V4nVY0DfVIO+YyKJkHD18Od50OBTNg2kkw7WRvnTfVa80SkYSTlhxmamEGUwsHfphVW2c3m/Y0sX5HI+t3NrJuRwO/e3U7v1q1FfBGcM8szmLexByKs1Op3tfO7sY29vjr/p6znRIOUVaYOexEcCgqERyO5lp47QHY+oK3tNV7+3Mm+4nBTw5Fs5QYRAKup8exra5lf3LoXdc2dzAuJ5WS7LT965I+r8flpJKbnnxYDeCqGhoNPT1QvcFPCs976ybvObdkFHlJYf7HYO4yCOthIyIyumJWNWRmZwM/A8LAL5xz3+vz/inAT4EPAJc45x6LZjxRFQp5YwzGzYfFV3ljEPZWHEgKW1bAhicgeyIsvhKOuwIyCmIdtYhI9EoEZhYG3gE+DFQBq4FPOOfWRxxTCuQAXwWeGEwiGLMlgvfT0w0b/wKrboMtz0JSGnzgIjj+cxqkJiJRF6sSwWJgk3Ouwg/iIeB8YH8icM5V+u8NoQNXnAqFYc5HvGXPBnjpdnjtYXjlfu/Zycf/M8w+S3Maicioi+aY7EnAtojXVf6+ITOzq82s3MzKq6urRyS4mCqZCx/9GXx5vfdozNoKeOgT8PNj4cVboK0h1hGKSIDExeQczrk7nXMLnXMLi4uLYx3OyMko8J6TfP1rcOG9kD0Bnv4G/HAm3HsePPtDb3qL7s5YRyoiCSyaVUPbgSkRryf7+6SvcBLM/wdv2fEqvPGY147wzLfhGSAly+t1VHaqV4007kivcVpEZAREMxGsBmaZWRleArgE+GQUr5cYJh5z4MlozbVQudLrcbTlWa+xGSC9AMqWeolh2klQNEeJQUSGLarjCMzsHLzuoWHgHufcd8zsW0C5c+4JM1sE/A7IB9qAXc65Q3ahidteQyOhYbuXGCqe9RJDo1/ASs2FycfB5MUweRFMXgjpebGNVUTGFA0oS0S94xS2vQTbXoaq1bBnPTi/A1bRHJiyyEsOUxar1CAScJprKBGZQeEMb1ng17i174Ptr0DVy7BtNbz1J2+CPICUbJjwAZhwNIz310WzNZW2iCgRJJTUbJh+qreAV2qo3ewlhqpy2PU6lP8Sulq995PSvMFskcmhZB4kp8XuHkRk1KlqKGh6uqFmo5cUdr7mL69Duz92IZQEedMgv/TgpaDM25+WE7vYRWTYVDUkB4TCUHKEt3zgIm+fc1BX6SeH12HvZu/19jUHZlTtlVF4cILImwq5U7wkkTtZpQmROKREIF57Q0GZt8w7/+D3WuugbquXGOoqoW7LgSSx7vfgug8+PmtcRHKYCnlTIHcqpGR617GQt9C73WedkuklFU21ITJqlAjk0NLzvWXigve+190F+3ZC/bvQsM1b12+F+m3ewLgN/wM9wxgVnZTulVjGzYeS+TBunrfOSqBR5SJjiBKBDF84yfuLP29K/+/3dHvPZKjfBl1tftdW561d37X/XmudNynf7nXw9lMHej0BZJYcSArj5nlzNhUf4ZUiRGTYlAgkekJhyJnoLcPVtMdLCnvWe+vd66D8bi+x9Mqb6vV2Kj7iQHIomg0pAz9KEICuDi/xtO7113XQ0Qydrd75O1uhq93rZdXZdvA6Kc3rZTXpOK/H1ftdS2QMUyKQsS2rxFtmnH5gX0+3N5huzwaofuvAetPfIqqizGvMLpnrTebXVg8tew/86LfUQce+wcUQSobkdEhK9aqtktOgvQlef9i/VNhLRJOO8RLDxGO96470k+ic80aT17wDablQMN2rthM5TOo+Komju7P/BNG050BbR0aBN1dTRkGfff52Srb3g5+c7v3Vn5w+cMP1vl3eAL4dr3iN59tfOdDLqrfEMPFYrxE+qwSyxnvr7PHvX53VstcrBfVWk+3Z4C3tfaYoTy/wEkLhDG9dMB0KZnjX1BPwJIKmmBAZDc55vaq2v+Iva7xxGr0D+CKlZB9IClnjvMVC3nOvd6+Hpl0Hjk3L9dpFSuZ6bSNFc6C90Ut6tZu99d4KaKgCIv49p+VBziRvahELewnN+m6H/O2wNz9VZglkFnmxHbRd7CXIvvfb0QwtNdBS6yWvllpvaa7xSl6ZxRFJaoaXnA7jAewyfBpHIDIazA78VX7UP3r7enq86qim3V4JommP9yO/b7e3r2m3N35j326vWqt4Dsw448CPfsk8r2prMD+enW1e197exLB3s3c91+NVp7nuA2vn/O0Ob93T5VU5NddAZ3P/50/N9RJDcvqBH/3u9v6PDSV5Cay17sD8V3CgSqvAnx6lIKIkoyQRM0oEItEUCnk/nplF7/9saucO74cwOe3AYMHD0dEMzdXQVO2tm/dEvN7jJZwJC7wf7oxC794yCg9e0nK9e+nq8LoU7y+5bPanPVkN6357cJJIyfLGkORNhfxp790eyVHtzkFHk5eo2hq9mLPGBXZiRiUCkbFirPw1nJLpLfmlh3+upBQomuUtfXW1e4MVe0swveNQ6rZ60613NB18fHq+N1AxLRfCKX7jfSqEU73rhFMP3oeD1voDPcJa67w2nN7tnq4+sab5gyCnecknv/Tg7bTc995DT7fXu6yzFTpbDqy72rxSUVKqd96+63DqwEnHOS+27k5vvX+704shNXsYX8ShKRGISGwkpULxbG/py/ljSuoq/UGK73oJov5dv4tvvVfa6Grzqqe6Ovy1v/SOeE/N9do+0vP8RDLJW6flHeggkJrtlXjqe0fQb/Wmdu/bMJ+W55UcIn/0B6oaG4xwipcUQmFvcGZPp/eD33e0fqRzfwyLPjv8aw5AiUBExh4zv+qpACYdO/TP9/jtIIczzXrv9Cq9pZS6Sq9EkZzhL+kR6/SD9yWlej/oXe1esjrUurvT62ocSvLXvdtJ792eesLw7+cQlAhEJPGMxFxVh5peJcEEs2VERET2UyIQEQk4JQIRkYBTIhARCTglAhGRgFMiEBEJOCUCEZGAUyIQEQm4uJuG2syqga19dhcBNTEIJ1oS7X4g8e4p0e4HEu+eEu1+4PDuaZpzrt8Hf8ddIuiPmZUPNM92PEq0+4HEu6dEux9IvHtKtPuB6N2TqoZERAJOiUBEJOASJRHcGesARlii3Q8k3j0l2v1A4t1Tot0PROmeEqKNQEREhi9RSgQiIjJMSgQiIgEX14nAzM42s7fNbJOZ3RDreEaCmVWa2RtmttbMymMdz3CY2T1mtsfM3ozYV2Bm/2tmG/11fixjHIoB7udGM9vuf09rzeycWMY4FGY2xcyeMbP1ZrbOzK7398fzdzTQPcXl92RmaWb2spm95t/Pf/j7y8zsJf8372EzSxmR68VrG4GZhYF3gA8DVcBq4BPOufUxDewwmVklsNA5F7cDYczsFKAJuN85d6S/7wfAXufc9/ykne+c+9dYxjlYA9zPjUCTc+5HsYxtOMxsAjDBOfeKmWUDa4CPAZ8hfr+jge7pIuLwezIzAzKdc01mlgw8B1wPfBn4rXPuITO7HXjNOXfb4V4vnksEi4FNzrkK51wH8BBwfoxjEsA5twLY22f3+cB9/vZ9eP9I48IA9xO3nHM7nXOv+Nv7gA3AJOL7OxronuKS8zT5L5P9xQFnAI/5+0fsO4rnRDAJ2Bbxuoo4/uIjOOAvZrbGzK6OdTAjaJxzbqe/vQsYF8tgRsh1Zva6X3UUN9UokcysFDgGeIkE+Y763BPE6fdkZmEzWwvsAf4X2AzUO+e6/ENG7DcvnhNBolrinDsW+AhwrV8tkVCcVx8Zn3WSB9wGzAAWADuB/45tOENnZlnA48AXnXONke/F63fUzz3F7ffknOt2zi0AJuPVgBwRrWvFcyLYDkyJeD3Z3xfXnHPb/fUe4Hd4/wEkgt1+PW5vfe6eGMdzWJxzu/1/qD3AXcTZ9+TXOz8O/MY591t/d1x/R/3dU7x/TwDOuXrgGeBEIM/Mkvy3Ruw3L54TwWpglt+KngJcAjwR45gOi5ll+g1dmFkmcCbw5qE/FTeeAD7tb38a+EMMYzlsvT+Yvn8gjr4nvyHybmCDc+7HEW/F7Xc00D3F6/dkZsVmludvp+N1itmAlxD+0T9sxL6juO01BOB3BfspEAbucc59J8YhHRYzm45XCgBIAh6Ix3sysweB0/CmzN0NfBP4PfAIMBVvGvGLnHNx0QA7wP2chlfd4IBK4JqI+vUxzcyWACuBN4Aef/c38OrU4/U7GuiePkEcfk9m9gG8xuAw3h/sjzjnvuX/RjwEFACvApc559oP+3rxnAhEROTwxXPVkIiIjAAlAhGRgFMiEBEJOCUCEZGAUyIQEQk4JQKJK2ZWGDGT5K4+M0seciZGM1toZjcN4hovjFCsp5lZQ0R8a83sQyNxbv/8nzGzm0fqfBJcSe9/iMjY4ZyrxesX3u8MoGaWFDEXS9/PlgPvO7W3c+6kkYkWgJXOufNG8HwiI04lAol7Znavmd1uZi8BPzCzxWb2opm9amYvmNkc/7jTzOyP/vaN/iRky82swsy+EHG+pojjl5vZY2b2lpn9xh/Bipmd4+9bY2Y39Z53kPGWRpxvg3/+DP+9D/pxv+HHl+rvX+Tfy2vmzVOf7Z9uopk9Zd4zBH7gHxv2/z950z/Plw7//2VJZCoRSKKYDJzknOs2sxxgqXOuy6+K+S/ggn4+cwRwOpANvG1mtznnOvsccwwwH9gBPA+cbN4Dg+4ATnHObfFHHg9kqT+DZK8LgG5gDvBZ59zzZnYP8C9+Nc+9wAedc++Y2f3AP5vZrcDDwMXOudX+/bX651vgx9ju38PPgRJgUsSzE/IO/X+dBJ1KBJIoHnXOdfvbucCj5j1R7Cd4P+T9+ZNzrt1/CNAe+p92+WXnXJU/adlaoBQvgVQ457b4xxwqEax0zi2IWDb7+7c55573t38NLMFLDlucc+/4++8DTvH373TOrQZwzjVGVH/9zTnX4JxrA9YD04AKYLqZ/dzMzgYOmllUpC8lAkkUzRHb/wk84/9F/FEgbYDPRM7R0k3/JeTBHDMcfed2Ge5cL++JzzlXBxwNLAc+B/ximOeWgFAikESUy4HpeT8ThfO/jfcXd6n/+uJhnGOqmZ3ob38S71GEbwOlZjbT33858Ky/f4KZLQIws+yIqYjfw8yKgJBz7nHg34BjhxGfBIgSgSSiHwDfNbNXiUI7mHOuFfgX4CkzWwPsAxoGOHxpn+6jvVMIv4334KENQD5wm1+9cwVetVbvLJq3+49ivRj4uZm9hve0qoFKOeA9tWq53zbxa+Drh3XDkvA0+6jIMJhZlv9gcQNuATY6534yyM+WAn/sbcwViTWVCESG5yr/L+51eFVRd8Q4HpFhU4lARCTgVCIQEQk4JQIRkYBTIhARCTglAhGRgFMiEBEJuP8Ph+iXJqAzCZcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이제는 teacher의 지식을 증류하여 transfer할 student model을 정의한다\n",
        "# Teacher모델보다 작은 규모의 Student모델에 지식을 전달하면\n",
        "# model compression의 효과가 있어 학습 속도와 성능 모두 긍정적인 효과를 보인다\n",
        "class Student(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(28*28,800)\n",
        "    self.bn1 = nn.BatchNorm1d(800)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(800,800)\n",
        "    self.bn2 = nn.BatchNorm1d(800)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.fc3 = nn.Linear(800,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1,28*28)\n",
        "    x = self.fc1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "5Fjsgodb2Gqx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Student모델에 input을 넣어서 출력을 정상적으로 나오는지 Test하기\n",
        "x = torch.randn(16,1,28,28).to(device)\n",
        "student = Student().to(device)\n",
        "output = student(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErhFXpG328lB",
        "outputId": "e64504c1-9b32-4cf4-d546-62462cd70c77"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Student 모델의 가중치를 초기화하는 함수를 정의하고\n",
        "# 해당 모델에 적용한다\n",
        "\n",
        "def initialize_weights(model):\n",
        "  classname = model.__class__.__name__\n",
        "\n",
        "  # 만약 FC Layer라면 다음과 같이 가중치를 초기화한다\n",
        "  if classname.find(\"Linear\") != -1:\n",
        "    nn.init.normal_(model.weight.data, 0.0, 0.02) # 평균이 0이고 표준편차0.02인 가우시안 정규분포로 초기화\n",
        "    nn.init.constant_(model.bias.data,0) # Bias는 0으로 초기화\n",
        "\n",
        "  # batch normalization 게층은 다음과 같이 초기화\n",
        "  elif classname.find(\"BatchNorm\") != -1:\n",
        "    nn.init.normal_(model.weight.data, 1.0, 0.02) # 평균이 1이고 표준편차 0.02인 가우시안 정규분포 난수\n",
        "    nn.init.constant_(model.bias.data, 0)\n",
        "\n",
        "student.apply(initialize_weights) # teacher모델에 해당 가중치 초기화 함수를 적용한다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXoI24td3UdZ",
        "outputId": "5f34be5c-2b0d-4b3b-9265-056a01aa8c6b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Student(\n",
              "  (fc1): Linear(in_features=784, out_features=800, bias=True)\n",
              "  (bn1): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=800, out_features=800, bias=True)\n",
              "  (bn2): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu2): ReLU()\n",
              "  (fc3): Linear(in_features=800, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher model의 soft label을 사용하여 student knowledge distillation loss로 학습\n",
        "teacher = Teacher().to(device)\n",
        "teacher.load_state_dict(torch.load(\"./models/teacher_weights.pt\"))\n",
        "\n",
        "student = Student().to(device)\n",
        "\n",
        "opt = optim.Adam(student.parameters())"
      ],
      "metadata": {
        "id": "k0cdRGOw3aOi"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Knowledge Distillation Loss\n",
        "# student 모델을 어떻게 학습 시키는가?\n",
        "# 후에 정의할 Knowledge Distillation Loss를 최소화하도록 학습한다\n",
        "# 이는 Student model의 Cross Entropy Loss와 Distillation Loss를 더한 값이다\n",
        "\n",
        "# y : student모델의 soft predicetion\n",
        "# teacher_scores : teacher모델의 soft prediction\n",
        "# labels : student의 Hard Label\n",
        "# T : Temperature\n",
        "def distillation(y, labels, teacher_scores, T, alpha):\n",
        "    # distillation loss + classification loss\n",
        "    # y: student\n",
        "    # labels: hard label\n",
        "    # teacher_scores: soft label\n",
        "    return nn.KLDivLoss()(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2.0 + alpha) + F.cross_entropy(y,labels) * (1.-alpha)\n",
        "\n",
        "# val loss\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "n7WXeBkRVs_a"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 batch를 학습하고 손실함수값과 맞춘 개수를 반환하는 함수\n",
        "def distill_loss_batch(output, target, teacher_output, loss_fn=distillation, opt=opt):\n",
        "    loss_b = loss_fn(output, target, teacher_output, T=20.0, alpha=0.7)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss_b.item(), metric_b"
      ],
      "metadata": {
        "id": "g_lh_fRLbvDC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "# 100 epoch분량 학습\n",
        "num_epochs= 100\n",
        "\n",
        "loss_history = {'train': [], 'val': []}\n",
        "metric_history = {'train': [], 'val': []}\n",
        "\n",
        "best_loss = float('inf')\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "    # train\n",
        "    student.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(train_dl.dataset)\n",
        "\n",
        "    for xb, yb in train_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        output = student(xb)\n",
        "        teacher_output = teacher(xb).detach()\n",
        "        loss_b, metric_b = distill_loss_batch(output, yb, teacher_output, loss_fn=distillation, opt=opt)\n",
        "        running_loss += loss_b\n",
        "        running_metric_b = metric_b\n",
        "    train_loss = running_loss / len_data\n",
        "    train_metric = running_metric / len_data\n",
        "\n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # validation\n",
        "    student.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_metric = loss_epoch(student, loss_func, val_dl)\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "\n",
        "    lr_scheduler.step(val_loss)\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V5YoCgAcc3J",
        "outputId": "f0142fb9-e3c6-4e2e-80b6-2bc90db88544"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/99, current lr= 0.001\n",
            "train loss: 0.032122, val loss: 0.000830, accuracy: 96.97, time: 0.2134 min\n",
            "----------\n",
            "Epoch 1/99, current lr= 0.001\n",
            "train loss: 0.027966, val loss: 0.000698, accuracy: 97.66, time: 0.4275 min\n",
            "----------\n",
            "Epoch 2/99, current lr= 0.001\n",
            "train loss: 0.027443, val loss: 0.000665, accuracy: 97.68, time: 0.6394 min\n",
            "----------\n",
            "Epoch 3/99, current lr= 0.001\n",
            "train loss: 0.027079, val loss: 0.000637, accuracy: 97.73, time: 0.8525 min\n",
            "----------\n",
            "Epoch 4/99, current lr= 0.001\n",
            "train loss: 0.026977, val loss: 0.000597, accuracy: 97.85, time: 1.0638 min\n",
            "----------\n",
            "Epoch 5/99, current lr= 0.001\n",
            "train loss: 0.026813, val loss: 0.000589, accuracy: 97.89, time: 1.2774 min\n",
            "----------\n",
            "Epoch 6/99, current lr= 0.001\n",
            "train loss: 0.026733, val loss: 0.000561, accuracy: 97.94, time: 1.4912 min\n",
            "----------\n",
            "Epoch 7/99, current lr= 0.001\n",
            "train loss: 0.026704, val loss: 0.000573, accuracy: 97.98, time: 1.7032 min\n",
            "----------\n",
            "Epoch 8/99, current lr= 0.001\n",
            "train loss: 0.026576, val loss: 0.000548, accuracy: 98.02, time: 1.9155 min\n",
            "----------\n",
            "Epoch 9/99, current lr= 0.001\n",
            "train loss: 0.026532, val loss: 0.000536, accuracy: 98.09, time: 2.1272 min\n",
            "----------\n",
            "Epoch 10/99, current lr= 0.001\n",
            "train loss: 0.026407, val loss: 0.000551, accuracy: 97.96, time: 2.3388 min\n",
            "----------\n",
            "Epoch 11/99, current lr= 0.001\n",
            "train loss: 0.026283, val loss: 0.000536, accuracy: 97.97, time: 2.5516 min\n",
            "----------\n",
            "Epoch 12/99, current lr= 0.001\n",
            "train loss: 0.026230, val loss: 0.000537, accuracy: 98.08, time: 2.7660 min\n",
            "----------\n",
            "Epoch 13/99, current lr= 0.001\n",
            "train loss: 0.026321, val loss: 0.000537, accuracy: 98.09, time: 2.9780 min\n",
            "----------\n",
            "Epoch 14/99, current lr= 0.001\n",
            "train loss: 0.026008, val loss: 0.000522, accuracy: 98.06, time: 3.1893 min\n",
            "----------\n",
            "Epoch 15/99, current lr= 0.001\n",
            "train loss: 0.025992, val loss: 0.000501, accuracy: 98.20, time: 3.4011 min\n",
            "----------\n",
            "Epoch 16/99, current lr= 0.001\n",
            "train loss: 0.026058, val loss: 0.000509, accuracy: 98.18, time: 3.6133 min\n",
            "----------\n",
            "Epoch 17/99, current lr= 0.001\n",
            "train loss: 0.026184, val loss: 0.000515, accuracy: 98.12, time: 3.8254 min\n",
            "----------\n",
            "Epoch 18/99, current lr= 0.001\n",
            "train loss: 0.026041, val loss: 0.000539, accuracy: 98.11, time: 4.0404 min\n",
            "----------\n",
            "Epoch 19/99, current lr= 0.001\n",
            "train loss: 0.026087, val loss: 0.000500, accuracy: 98.15, time: 4.2509 min\n",
            "----------\n",
            "Epoch 20/99, current lr= 0.001\n",
            "train loss: 0.025944, val loss: 0.000519, accuracy: 98.10, time: 4.4624 min\n",
            "----------\n",
            "Epoch 21/99, current lr= 0.001\n",
            "train loss: 0.025909, val loss: 0.000490, accuracy: 98.16, time: 4.6741 min\n",
            "----------\n",
            "Epoch 22/99, current lr= 0.001\n",
            "train loss: 0.026012, val loss: 0.000481, accuracy: 98.25, time: 4.8873 min\n",
            "----------\n",
            "Epoch 23/99, current lr= 0.001\n",
            "train loss: 0.025944, val loss: 0.000480, accuracy: 98.25, time: 5.1001 min\n",
            "----------\n",
            "Epoch 24/99, current lr= 0.001\n",
            "train loss: 0.026019, val loss: 0.000503, accuracy: 98.07, time: 5.3142 min\n",
            "----------\n",
            "Epoch 25/99, current lr= 0.001\n",
            "train loss: 0.025845, val loss: 0.000469, accuracy: 98.15, time: 5.5288 min\n",
            "----------\n",
            "Epoch 26/99, current lr= 0.001\n",
            "train loss: 0.025817, val loss: 0.000468, accuracy: 98.21, time: 5.7405 min\n",
            "----------\n",
            "Epoch 27/99, current lr= 0.001\n",
            "train loss: 0.025951, val loss: 0.000491, accuracy: 98.20, time: 5.9555 min\n",
            "----------\n",
            "Epoch 28/99, current lr= 0.001\n",
            "train loss: 0.025897, val loss: 0.000469, accuracy: 98.21, time: 6.1681 min\n",
            "----------\n",
            "Epoch 29/99, current lr= 0.001\n",
            "train loss: 0.025853, val loss: 0.000483, accuracy: 98.17, time: 6.3771 min\n",
            "----------\n",
            "Epoch 30/99, current lr= 0.001\n",
            "train loss: 0.025849, val loss: 0.000476, accuracy: 98.26, time: 6.5895 min\n",
            "----------\n",
            "Epoch 31/99, current lr= 0.001\n",
            "train loss: 0.025647, val loss: 0.000501, accuracy: 98.20, time: 6.8012 min\n",
            "----------\n",
            "Epoch 32/99, current lr= 0.001\n",
            "train loss: 0.025905, val loss: 0.000498, accuracy: 98.14, time: 7.0116 min\n",
            "----------\n",
            "Epoch 33/99, current lr= 0.001\n",
            "train loss: 0.025821, val loss: 0.000501, accuracy: 98.22, time: 7.2243 min\n",
            "----------\n",
            "Epoch 34/99, current lr= 0.001\n",
            "train loss: 0.025845, val loss: 0.000481, accuracy: 98.14, time: 7.4350 min\n",
            "----------\n",
            "Epoch 35/99, current lr= 0.001\n",
            "train loss: 0.025688, val loss: 0.000473, accuracy: 98.22, time: 7.6477 min\n",
            "----------\n",
            "Epoch 36/99, current lr= 0.001\n",
            "train loss: 0.025685, val loss: 0.000495, accuracy: 98.16, time: 7.8590 min\n",
            "----------\n",
            "Epoch 37/99, current lr= 0.001\n",
            "train loss: 0.025729, val loss: 0.000494, accuracy: 98.23, time: 8.0723 min\n",
            "----------\n",
            "Epoch 38/99, current lr= 0.001\n",
            "train loss: 0.025628, val loss: 0.000469, accuracy: 98.16, time: 8.2827 min\n",
            "----------\n",
            "Epoch 39/99, current lr= 0.001\n",
            "train loss: 0.025795, val loss: 0.000517, accuracy: 98.18, time: 8.4921 min\n",
            "----------\n",
            "Epoch 40/99, current lr= 0.001\n",
            "train loss: 0.025695, val loss: 0.000486, accuracy: 98.22, time: 8.7029 min\n",
            "----------\n",
            "Epoch 41/99, current lr= 0.001\n",
            "train loss: 0.025785, val loss: 0.000466, accuracy: 98.30, time: 8.9149 min\n",
            "----------\n",
            "Epoch 42/99, current lr= 0.001\n",
            "train loss: 0.025712, val loss: 0.000491, accuracy: 98.22, time: 9.1261 min\n",
            "----------\n",
            "Epoch 43/99, current lr= 0.001\n",
            "train loss: 0.025667, val loss: 0.000467, accuracy: 98.29, time: 9.3380 min\n",
            "----------\n",
            "Epoch 44/99, current lr= 0.001\n",
            "train loss: 0.025587, val loss: 0.000554, accuracy: 98.36, time: 9.5498 min\n",
            "----------\n",
            "Epoch 45/99, current lr= 0.001\n",
            "train loss: 0.025569, val loss: 0.000463, accuracy: 98.38, time: 9.7616 min\n",
            "----------\n",
            "Epoch 46/99, current lr= 0.001\n",
            "train loss: 0.025604, val loss: 0.000486, accuracy: 98.25, time: 9.9735 min\n",
            "----------\n",
            "Epoch 47/99, current lr= 0.001\n",
            "train loss: 0.025560, val loss: 0.000509, accuracy: 98.23, time: 10.1847 min\n",
            "----------\n",
            "Epoch 48/99, current lr= 0.001\n",
            "train loss: 0.025662, val loss: 0.000478, accuracy: 98.23, time: 10.3940 min\n",
            "----------\n",
            "Epoch 49/99, current lr= 0.001\n",
            "train loss: 0.025646, val loss: 0.000465, accuracy: 98.30, time: 10.6074 min\n",
            "----------\n",
            "Epoch 50/99, current lr= 0.001\n",
            "train loss: 0.025660, val loss: 0.000469, accuracy: 98.28, time: 10.8194 min\n",
            "----------\n",
            "Epoch 51/99, current lr= 0.001\n",
            "train loss: 0.025676, val loss: 0.000485, accuracy: 98.23, time: 11.0278 min\n",
            "----------\n",
            "Epoch 52/99, current lr= 0.001\n",
            "train loss: 0.025548, val loss: 0.000459, accuracy: 98.34, time: 11.2373 min\n",
            "----------\n",
            "Epoch 53/99, current lr= 0.001\n",
            "train loss: 0.025616, val loss: 0.000490, accuracy: 98.32, time: 11.4466 min\n",
            "----------\n",
            "Epoch 54/99, current lr= 0.001\n",
            "train loss: 0.025439, val loss: 0.000486, accuracy: 98.18, time: 11.6571 min\n",
            "----------\n",
            "Epoch 55/99, current lr= 0.001\n",
            "train loss: 0.025575, val loss: 0.000475, accuracy: 98.27, time: 11.8660 min\n",
            "----------\n",
            "Epoch 56/99, current lr= 0.001\n",
            "train loss: 0.025560, val loss: 0.000461, accuracy: 98.29, time: 12.0778 min\n",
            "----------\n",
            "Epoch 57/99, current lr= 0.001\n",
            "train loss: 0.025532, val loss: 0.000461, accuracy: 98.26, time: 12.2878 min\n",
            "----------\n",
            "Epoch 58/99, current lr= 0.001\n",
            "train loss: 0.025669, val loss: 0.000467, accuracy: 98.31, time: 12.4967 min\n",
            "----------\n",
            "Epoch 59/99, current lr= 0.001\n",
            "train loss: 0.025478, val loss: 0.000463, accuracy: 98.34, time: 12.7070 min\n",
            "----------\n",
            "Epoch 60/99, current lr= 0.001\n",
            "train loss: 0.025582, val loss: 0.000465, accuracy: 98.30, time: 12.9155 min\n",
            "----------\n",
            "Epoch 61/99, current lr= 0.001\n",
            "train loss: 0.025623, val loss: 0.000445, accuracy: 98.31, time: 13.1249 min\n",
            "----------\n",
            "Epoch 62/99, current lr= 0.001\n",
            "train loss: 0.025583, val loss: 0.000476, accuracy: 98.25, time: 13.3357 min\n",
            "----------\n",
            "Epoch 63/99, current lr= 0.001\n",
            "train loss: 0.025623, val loss: 0.000461, accuracy: 98.28, time: 13.5457 min\n",
            "----------\n",
            "Epoch 64/99, current lr= 0.001\n",
            "train loss: 0.025411, val loss: 0.000463, accuracy: 98.35, time: 13.7559 min\n",
            "----------\n",
            "Epoch 65/99, current lr= 0.001\n",
            "train loss: 0.025483, val loss: 0.000471, accuracy: 98.26, time: 13.9647 min\n",
            "----------\n",
            "Epoch 66/99, current lr= 0.001\n",
            "train loss: 0.025632, val loss: 0.000456, accuracy: 98.31, time: 14.1750 min\n",
            "----------\n",
            "Epoch 67/99, current lr= 0.001\n",
            "train loss: 0.025490, val loss: 0.000456, accuracy: 98.30, time: 14.3843 min\n",
            "----------\n",
            "Epoch 68/99, current lr= 0.001\n",
            "train loss: 0.025507, val loss: 0.000499, accuracy: 98.26, time: 14.5931 min\n",
            "----------\n",
            "Epoch 69/99, current lr= 0.001\n",
            "train loss: 0.025584, val loss: 0.000475, accuracy: 98.30, time: 14.8056 min\n",
            "----------\n",
            "Epoch 70/99, current lr= 0.001\n",
            "train loss: 0.025477, val loss: 0.000453, accuracy: 98.33, time: 15.0144 min\n",
            "----------\n",
            "Epoch 71/99, current lr= 0.001\n",
            "train loss: 0.025697, val loss: 0.000477, accuracy: 98.37, time: 15.2237 min\n",
            "----------\n",
            "Epoch 72/99, current lr= 0.001\n",
            "train loss: 0.025305, val loss: 0.000478, accuracy: 98.21, time: 15.4320 min\n",
            "----------\n",
            "Epoch 73/99, current lr= 0.001\n",
            "train loss: 0.025552, val loss: 0.000485, accuracy: 98.29, time: 15.6432 min\n",
            "----------\n",
            "Epoch 74/99, current lr= 0.001\n",
            "train loss: 0.025539, val loss: 0.000461, accuracy: 98.28, time: 15.8544 min\n",
            "----------\n",
            "Epoch 75/99, current lr= 0.001\n",
            "train loss: 0.025609, val loss: 0.000445, accuracy: 98.38, time: 16.0652 min\n",
            "----------\n",
            "Epoch 76/99, current lr= 0.001\n",
            "train loss: 0.025384, val loss: 0.000467, accuracy: 98.35, time: 16.2766 min\n",
            "----------\n",
            "Epoch 77/99, current lr= 0.001\n",
            "train loss: 0.025585, val loss: 0.000447, accuracy: 98.29, time: 16.4847 min\n",
            "----------\n",
            "Epoch 78/99, current lr= 0.001\n",
            "train loss: 0.025463, val loss: 0.000475, accuracy: 98.26, time: 16.6951 min\n",
            "----------\n",
            "Epoch 79/99, current lr= 0.001\n",
            "train loss: 0.025516, val loss: 0.000499, accuracy: 98.21, time: 16.9034 min\n",
            "----------\n",
            "Epoch 80/99, current lr= 0.001\n",
            "train loss: 0.025632, val loss: 0.000470, accuracy: 98.21, time: 17.1120 min\n",
            "----------\n",
            "Epoch 81/99, current lr= 0.001\n",
            "train loss: 0.025603, val loss: 0.000449, accuracy: 98.37, time: 17.3230 min\n",
            "----------\n",
            "Epoch 82/99, current lr= 0.001\n",
            "train loss: 0.025407, val loss: 0.000449, accuracy: 98.36, time: 17.5354 min\n",
            "----------\n",
            "Epoch 83/99, current lr= 0.001\n",
            "train loss: 0.025545, val loss: 0.000439, accuracy: 98.27, time: 17.7464 min\n",
            "----------\n",
            "Epoch 84/99, current lr= 0.001\n",
            "train loss: 0.025224, val loss: 0.000450, accuracy: 98.34, time: 17.9554 min\n",
            "----------\n",
            "Epoch 85/99, current lr= 0.001\n",
            "train loss: 0.025487, val loss: 0.000448, accuracy: 98.29, time: 18.1652 min\n",
            "----------\n",
            "Epoch 86/99, current lr= 0.001\n",
            "train loss: 0.025545, val loss: 0.000463, accuracy: 98.30, time: 18.3757 min\n",
            "----------\n",
            "Epoch 87/99, current lr= 0.001\n",
            "train loss: 0.025446, val loss: 0.000455, accuracy: 98.34, time: 18.5846 min\n",
            "----------\n",
            "Epoch 88/99, current lr= 0.001\n",
            "train loss: 0.025339, val loss: 0.000455, accuracy: 98.31, time: 18.7972 min\n",
            "----------\n",
            "Epoch 89/99, current lr= 0.001\n",
            "train loss: 0.025570, val loss: 0.000462, accuracy: 98.25, time: 19.0077 min\n",
            "----------\n",
            "Epoch 90/99, current lr= 0.001\n",
            "train loss: 0.025259, val loss: 0.000435, accuracy: 98.38, time: 19.2173 min\n",
            "----------\n",
            "Epoch 91/99, current lr= 0.001\n",
            "train loss: 0.025331, val loss: 0.000452, accuracy: 98.32, time: 19.4279 min\n",
            "----------\n",
            "Epoch 92/99, current lr= 0.001\n",
            "train loss: 0.025233, val loss: 0.000467, accuracy: 98.34, time: 19.6378 min\n",
            "----------\n",
            "Epoch 93/99, current lr= 0.001\n",
            "train loss: 0.025441, val loss: 0.000465, accuracy: 98.19, time: 19.8494 min\n",
            "----------\n",
            "Epoch 94/99, current lr= 0.001\n",
            "train loss: 0.025325, val loss: 0.000454, accuracy: 98.35, time: 20.0581 min\n",
            "----------\n",
            "Epoch 95/99, current lr= 0.001\n",
            "train loss: 0.025469, val loss: 0.000457, accuracy: 98.25, time: 20.2701 min\n",
            "----------\n",
            "Epoch 96/99, current lr= 0.001\n",
            "train loss: 0.025380, val loss: 0.000483, accuracy: 98.32, time: 20.4795 min\n",
            "----------\n",
            "Epoch 97/99, current lr= 0.001\n",
            "train loss: 0.025402, val loss: 0.000479, accuracy: 98.34, time: 20.6890 min\n",
            "----------\n",
            "Epoch 98/99, current lr= 0.001\n",
            "train loss: 0.025446, val loss: 0.000456, accuracy: 98.36, time: 20.9007 min\n",
            "----------\n",
            "Epoch 99/99, current lr= 0.001\n",
            "train loss: 0.025392, val loss: 0.000465, accuracy: 98.27, time: 21.1112 min\n",
            "----------\n"
          ]
        }
      ]
    }
  ]
}